{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "L7ghu6aHf2dJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYldaZ_qJqpT"
      },
      "outputs": [],
      "source": [
        "def get_fisher_diag(model, dataset, params, empirical=True):\n",
        "  fisher = {}\n",
        "  for n, p in deepcopy(params).items():\n",
        "    p.data.zero_()\n",
        "    fisher[n] = p.data.clone().detach().requires_grad_()\n",
        "\n",
        "  model.eval()\n",
        "  for input, gt_label in dataset:\n",
        "    model.zero_grad()\n",
        "    output = model(input).view(1, -1)\n",
        "    if empirical:\n",
        "      label = gt_label\n",
        "    else:\n",
        "      label = output.max(1)[1].view(-1)\n",
        "\n",
        "    negloglikelihood = torch.nn.functional.nll_loss(torch.nn.functional.log_softmax(output, dim=1), label)\n",
        "    negloglikelihood.backward()\n",
        "\n",
        "    for n, p in model.named_parameters():\n",
        "      fisher[n].data += p.grad.data ** 2 / len(dataset)\n",
        "\n",
        "  fisher = {n: p for n, p in fisher.items()}\n",
        "  return fisher\n",
        "\n",
        "def get_ewc_loss(model, fisher, p_old):\n",
        "  loss = 0\n",
        "  for n, p in model.named_parameters():\n",
        "    _loss = fisher[n] * (p - p_old[n]) ** 2\n",
        "    loss += _loss.sum()\n",
        "  return loss\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation"
      ],
      "metadata": {
        "id": "alP8iQ-uf5-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fisher_diag(model, dataset, params, empirical=True):\n",
        "  fisher = {}\n",
        "  for n, p in deepcopy(params).items():\n",
        "    p.data.zero_()\n",
        "    fisher[n] = p.data.clone().detach().requires_grad_()\n",
        "\n",
        "  model.eval()\n",
        "  for input, target in dataset:\n",
        "    model.zero_grad()\n",
        "    output = model(input)\n",
        "    output = output.view(-1, output.size(-1))\n",
        "    # output = model(input).view(1, -1)\n",
        "    if empirical:\n",
        "      label = target.view(-1)\n",
        "    else:\n",
        "      label = torch.argmax(output, dim=1)\n",
        "\n",
        "    cross_entropy_loss = torch.nn.functional.cross_entropy(output, label)\n",
        "    cross_entropy_loss.backward()\n",
        "\n",
        "    for n, p in model.named_parameters():\n",
        "      fisher[n].data += p.grad.data ** 2 / len(dataset)\n",
        "\n",
        "  fisher = {n: p for n, p in fisher.items()}\n",
        "  return fisher\n",
        "\n",
        "def get_ewc_loss(model, fisher, p_old):\n",
        "  loss = 0\n",
        "  for n, p in model.named_parameters():\n",
        "    _loss = fisher[n] * (p - p_old[n]) ** 2\n",
        "    loss += _loss.sum()\n",
        "  return loss"
      ],
      "metadata": {
        "id": "26FtMebff7sz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}