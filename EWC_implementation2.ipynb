{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "b2NSA-U_0DhS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTtask1(datasets.FashionMNIST):\n",
        "  def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
        "    super(FashionMNISTtask1, self).__init__(root, train=train, transform=transform,\n",
        "                                            target_transform=target_transform,download=download)\n",
        "    self.classes = self.classes[:6]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img, target = super(FashionMNISTtask1, self).__getitem__(index)\n",
        "    if target < 6:\n",
        "        return img, target\n",
        "    else:\n",
        "        return img, -1"
      ],
      "metadata": {
        "id": "qSfxWcOn18kp"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTtask2(datasets.FashionMNIST):\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
        "        super(FashionMNISTtask2, self).__init__(root, train=train, transform=transform,\n",
        "                                                target_transform=target_transform,download=download)\n",
        "        self.classes = self.classes[6:]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = super(FashionMNISTtask2, self).__getitem__(index)\n",
        "        if target >= 6:\n",
        "            return img, target\n",
        "        else:\n",
        "            return img, -1"
      ],
      "metadata": {
        "id": "Nl-_I6Ry2BMR"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose([ToTensor(), Normalize((0.5), (0.5))])\n",
        "\n",
        "train_dataset_1 = FashionMNISTtask1(root='./data1', train=True, transform=transform, download=True)\n",
        "test_dataset_1 = FashionMNISTtask1(root='./data1', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "JvtnT5b32GBQ"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to display an image\n",
        "def show_image(image):\n",
        "    # Convert the PyTorch tensor to a numpy array and reshape it to (28, 28)\n",
        "    image = np.squeeze(image.numpy())\n",
        "    # Plot the image\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example: Display the first 10 images from the training dataset\n",
        "for i in range(10):\n",
        "    image, target = train_dataset_1[i]\n",
        "    print(\"Image shape:\", image.shape, \"Label:\", target)\n",
        "    show_image(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfhuczT7ejjR",
        "outputId": "6c8e573c-d971-45e6-fced-a7317c9b956d"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAKEElEQVR4nO3cPYucdRvG4f/sTHaXZNUoMb6lEURS+hX8ArZWgp/Awk78GvaCrVjY2FjYC4K1jaQQFlzRSIiz7rzYnU+71yV7Z7yf46g9mcnMbn65C6/Ffr/fDwAYYxw96zcAwOEQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFbX/Q8Xi8VNvg+eofv375c3H374YXnzxRdflDdjjHF+ft7azc0777xT3jx8+LC8+eqrr8qbq6ur8obpXef/VfakAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABDXPojHf8PZ2Vl5895775U3H3zwQXnz/vvvlzdjjHFxcVHe/P3335NsnnvuufLm5OSkvBljjAcPHpQ3X3/9dXmz3W7Lmy+//LK84TB5UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/Fm5smTJ+XN48ePy5tPPvmkvPn000/LmzHGePjwYXnzyiuvlDedQ3W///57edP5jsYY49tvvy1vvvnmm/Kmc1SR+fCkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4kso4Pj4ub/7444/y5rPPPitvxhjjo48+Km8uLy/Lm86V1M7n8MMPP5Q3Y4zx+eeflzdvvvlmefPrr7+WN8yHJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcBCP8eTJk/Lm3r175c2jR4/KmzHG+Pjjj8ubBw8elDcvv/xyefPzzz+XN7/99lt5M0bvM1+t6r/ii8WivGE+PCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhIN4jM1mM8nrdA66dV1cXJQ35+fn5c3t27fLmzfeeKO8GWOM7XZb3uz3+0k2zIcnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwEI9xdFT/t0HnaFrnoNsYYyyXy/Lm7t27rdc6ZIvForzpfE+rlb8W/p95UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIl68YZ2dn5c3JyUl5s16vy5sxegfxdrvdJK/TOVLX1Tlc2Nmcnp6WN8yHJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwpVUxmpV/zHoXAftXhTtXPqc6v1N9d7GGGOz2ZQ3nffXuRbLfHhSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgH8WgdTXv69Gl50z20NtXRue12W9507Pf7SV5njDEuLy8ney3mwZMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQDiIR+vgXEf3IN5ut5vktab6HLpWq/qva+cg3v3798sb5uOwfwsAmJQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOEg3sy8+OKL5U3neNxisShv9vt9eTPG4R+qq+oc+BujdxBvvV6XN3fu3ClvTk9Py5vOe+Pmzeu3DYB/RRQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwpXUmbm8vJxk0714OpWp3l/nWuyUV187F3AfP35c3rh4Oh+eFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCQbyZ6RyC6xxNY3qd7/bk5OQG3glz5kkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIBzEm5mpjtvtdrvy5ujosP8NMsc/U+f9bbfbSV6n83lz8w77JxqASYkCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEA7izczp6Wl5s9/vJ9ksFovyZozpDrRNdUywq/P5TfXdHh8flzfr9bq84eZ5UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/FmpnM0bapN59BaV/f43txM9Tl0DhBymHyTAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQrqTOzXC6f9Vs4CJ2LrFNdFO2+TufP1Pl56GxWK3+VzIUnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwxWpmOsfWtttteTPlwbmjo2n+7dL5M035OlN9Dp3v6YUXXihv/vzzz/KGm+dJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACAcxJuZW7dulTedQ2vd43Ydndea6rjdoZvq2OHJyUl5w2HypABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQDuLNzGpV/0o7B+eWy2V540jdv7PZbCZ5naurq/Kmc1SRw+SbBCBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgH8Wbm+Ph4ktfpHLfb7Xat13Jsra/zPXUO4t2+fbu84TD5bQMgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgXEmdmc6V1M4lzc1mU94sFovyhv/pXIvdbrflTedK6ltvvVXe/Pjjj+UNN8+TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEA4iDczr7/++iSv0znO1jm8N8YYu92uvFkul+VN9/1VdT67MXqfQ+cIYefY4cXFRXnDYfKkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAO4s3Mer0ub27dulXedI7HdY7UjdE76rbdbsub7vururq6au06769zRO/s7Ky8efToUXnDYfKkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAO4s3M999/X968/fbb5c3du3fLm7/++qu86eoc0dtsNuVN5zDglF577bXypnNM8KeffipvOEyeFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIxf6aZx47Vyf5bzg9PS1v3n333fLm3r175c0YY9y5c6e8WS6X5U3nSmrH0VHv32Kd66W//PJLefPdd9+VN0+fPi1vmN51/rr3pABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQDuLNTOd7uuaPwDPz0ksvlTevvvpqefP888+XNx3n5+eT7dbrdeu1qub4czdHDuIBUCIKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQKyu+x86XgUwf54UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiH8AHNKAX4Ph1REAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28]) Label: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_2 = FashionMNISTtask2(root='./data2', train=True, transform=transform, download=True)\n",
        "test_dataset_2 = FashionMNISTtask2(root='./data2', train=False, transform=transform, download=True)\n",
        "test_dataset_3 = datasets.FashionMNIST(\n",
        "    root='data3',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "yr4F5agU2Gio"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_filtered_first = [data for data in train_dataset_1 if data[1] != -1]\n",
        "test_dataset_filtered_first = [data for data in test_dataset_1 if data[1] != -1]\n",
        "\n",
        "train_dataset_filtered_second = [data for data in train_dataset_2 if data[1] != -1]\n",
        "test_dataset_filtered_second = [data for data in test_dataset_2 if data[1] != -1]"
      ],
      "metadata": {
        "id": "N8HwMD0z2IZc"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels_1 = set()\n",
        "unique_labels_2 = set()\n",
        "\n",
        "for _, target in train_dataset_filtered_first:\n",
        "    unique_labels_1.add(target)\n",
        "\n",
        "for _, target in train_dataset_filtered_second:\n",
        "    unique_labels_2.add(target)\n",
        "\n",
        "print(f\"First: {unique_labels_1}\")\n",
        "print(f\"Second: {unique_labels_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUz-SUDKsZuX",
        "outputId": "3dd4f5e9-1c97-4e68-a9c4-e8bbf487a28c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First: {0, 1, 2, 3, 4, 5}\n",
            "Second: {8, 9, 6, 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_first = DataLoader(train_dataset_filtered_first, batch_size=64, shuffle=True)\n",
        "test_dataloader_first = DataLoader(test_dataset_filtered_first, batch_size=256, shuffle=False)\n",
        "\n",
        "for X, y in train_dataloader_first:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"SHape of y: {y.shape}, dtype: {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_J6o_FR2Mh8",
        "outputId": "60e42189-d843-40f0-de4e-cb13fe9c40fa"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "SHape of y: torch.Size([64]), dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader_second = DataLoader(train_dataset_filtered_second, batch_size=64, shuffle=True)\n",
        "test_dataloader_second = DataLoader(test_dataset_filtered_second, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "OFGpnxZq2NYt"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataloader = DataLoader(test_dataset_3, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "dpjhj4M82QGR"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7raJ2RC2Toq",
        "outputId": "064cfb0a-ee88-4a2a-9911-46484710263b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_classes=10, hidden_size=512):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(28*28, hidden_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    #     self._initialize_weights()\n",
        "\n",
        "    # def _initialize_weights(self):\n",
        "    #     for m in self.modules():\n",
        "    #         if isinstance(m, nn.Linear):\n",
        "    #             nn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
        "    #         elif isinstance(m, nn.Conv2d):\n",
        "    #             nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "C5nQoXPk2Wbo"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch+1) * len(X)\n",
        "      print(f\"Loss: {loss:>7f}, {current:>5d}/{size:>5d}\")"
      ],
      "metadata": {
        "id": "tyhb4Zo4230I"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}, Avg Loss: {test_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "hZThNdfT26Kg"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(num_classes=10, hidden_size=512).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "O8cy0wv-28X4"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n---------------------------\")\n",
        "  train(train_dataloader_first, model, loss_fn, optimizer)\n",
        "  test(test_dataloader_first, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "torch.save(model.state_dict(), \"model_old.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO9q7xFU4UUI",
        "outputId": "e9356d64-05d5-43fe-cb2b-1dc5e53211d6"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "---------------------------\n",
            "Loss: 2.290051,    64/36000\n",
            "Loss: 0.376325,  6464/36000\n",
            "Loss: 0.346875, 12864/36000\n",
            "Loss: 0.275218, 19264/36000\n",
            "Loss: 0.211062, 25664/36000\n",
            "Loss: 0.223819, 32064/36000\n",
            "Test Error: \n",
            " Accuracy: 88.9, Avg Loss: 0.301338\n",
            "\n",
            "Epoch 2\n",
            "---------------------------\n",
            "Loss: 0.399667,    64/36000\n",
            "Loss: 0.289187,  6464/36000\n",
            "Loss: 0.353504, 12864/36000\n",
            "Loss: 0.220276, 19264/36000\n",
            "Loss: 0.306884, 25664/36000\n",
            "Loss: 0.255213, 32064/36000\n",
            "Test Error: \n",
            " Accuracy: 89.6, Avg Loss: 0.275398\n",
            "\n",
            "Epoch 3\n",
            "---------------------------\n",
            "Loss: 0.166455,    64/36000\n",
            "Loss: 0.263506,  6464/36000\n",
            "Loss: 0.260480, 12864/36000\n",
            "Loss: 0.280514, 19264/36000\n",
            "Loss: 0.290238, 25664/36000\n",
            "Loss: 0.292352, 32064/36000\n",
            "Test Error: \n",
            " Accuracy: 90.5, Avg Loss: 0.266529\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def val(epoch):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(eval_dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            _, predicted_old = outputs.max(1)\n",
        "            print(predicted_old)\n",
        "            total += len(y)\n",
        "            correct += predicted_old.eq(y).sum().item()\n",
        "        print(f\"Validation Acc: {100. * correct / total}\\n\")"
      ],
      "metadata": {
        "id": "RZmhDHNfIypc"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_50xg7ygJGMA",
        "outputId": "069b67de-3f01-461e-b758-663c6b20ec1e"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 0, 5, 2, 3, 0, 4, 5, 5, 5, 0, 4, 2, 5, 4, 3, 5, 5, 4, 4, 0, 0, 0, 2,\n",
            "        0, 0, 2, 2, 5, 5, 5, 5, 4, 1, 5, 5, 5, 5, 1, 4, 4, 1, 5, 0, 0, 1, 5, 5,\n",
            "        3, 2, 1, 5, 5, 1, 5, 5, 5, 4, 2, 4, 5, 5, 5, 0, 2, 0, 5, 5, 2, 3, 3, 3,\n",
            "        4, 4, 0, 3, 0, 4, 3, 2, 1, 5, 0, 2, 0, 0, 5, 0, 4, 2, 4, 5, 4, 5, 3, 2,\n",
            "        5, 5, 5, 5, 2, 0, 3, 4, 0, 0, 3, 5, 5, 4, 0, 1, 0, 1, 5, 3, 5, 4, 2, 0,\n",
            "        3, 5, 5, 5, 0, 2, 0, 4, 5, 1, 0, 4, 5, 4, 2, 3, 1, 5, 2, 0, 5, 5, 4, 5,\n",
            "        0, 2, 5, 4, 3, 0, 1, 5, 0, 5, 3, 2, 5, 5, 3, 5, 5, 5, 1, 2, 5, 5, 2, 5,\n",
            "        1, 5, 3, 1, 2, 5, 3, 0, 5, 0, 4, 2, 0, 3, 2, 0, 4, 4, 5, 5, 0, 5, 1, 0,\n",
            "        5, 2, 5, 5, 3, 2, 1, 1, 4, 4, 5, 2, 5, 4, 2, 0, 5, 4, 5, 2, 3, 5, 3, 5,\n",
            "        5, 2, 4, 3, 1, 2, 4, 2, 5, 5, 3, 3, 0, 2, 4, 3, 1, 3, 0, 3, 0, 4, 2, 0,\n",
            "        5, 0, 5, 2, 5, 2, 5, 5, 2, 3, 3, 2, 5, 4, 5, 5])\n",
            "tensor([5, 5, 2, 4, 0, 2, 1, 5, 1, 5, 5, 0, 5, 5, 4, 3, 0, 4, 2, 2, 2, 1, 0, 1,\n",
            "        5, 3, 5, 5, 2, 1, 0, 4, 5, 5, 5, 2, 3, 0, 4, 5, 5, 2, 5, 2, 3, 5, 5, 2,\n",
            "        2, 0, 2, 2, 2, 0, 4, 4, 3, 1, 0, 0, 3, 0, 4, 0, 2, 5, 2, 5, 3, 5, 5, 5,\n",
            "        4, 3, 4, 2, 0, 5, 5, 4, 5, 0, 1, 5, 0, 4, 0, 4, 4, 5, 0, 2, 4, 5, 2, 1,\n",
            "        0, 2, 3, 5, 2, 5, 1, 5, 0, 4, 1, 2, 0, 0, 5, 4, 4, 3, 5, 5, 3, 5, 0, 3,\n",
            "        4, 4, 1, 0, 5, 0, 5, 4, 2, 5, 0, 5, 0, 3, 3, 0, 1, 0, 4, 0, 3, 2, 2, 1,\n",
            "        4, 5, 5, 5, 5, 5, 5, 4, 3, 4, 0, 2, 3, 3, 0, 0, 5, 5, 5, 3, 0, 5, 4, 5,\n",
            "        0, 0, 1, 5, 1, 3, 5, 4, 5, 3, 3, 0, 1, 5, 1, 1, 4, 1, 4, 2, 1, 5, 5, 4,\n",
            "        1, 5, 0, 2, 0, 5, 2, 0, 5, 1, 2, 2, 2, 2, 4, 0, 5, 5, 5, 0, 2, 5, 4, 5,\n",
            "        5, 0, 5, 4, 4, 5, 2, 2, 3, 5, 4, 0, 3, 1, 4, 0, 1, 0, 1, 0, 3, 1, 2, 2,\n",
            "        5, 0, 4, 4, 5, 5, 2, 2, 0, 1, 0, 3, 4, 5, 4, 5])\n",
            "tensor([0, 5, 5, 5, 3, 5, 0, 2, 5, 0, 5, 0, 5, 5, 1, 2, 5, 4, 4, 5, 5, 5, 2, 3,\n",
            "        1, 0, 4, 2, 4, 5, 2, 2, 2, 2, 5, 2, 1, 4, 1, 5, 2, 0, 5, 3, 5, 5, 1, 2,\n",
            "        5, 5, 0, 4, 5, 3, 4, 4, 0, 0, 2, 5, 4, 2, 5, 5, 2, 4, 4, 5, 5, 4, 5, 4,\n",
            "        4, 0, 3, 5, 5, 3, 3, 1, 5, 5, 2, 2, 2, 1, 5, 0, 1, 3, 4, 5, 0, 5, 0, 4,\n",
            "        4, 5, 4, 5, 1, 3, 4, 4, 1, 5, 2, 2, 0, 3, 4, 2, 4, 5, 4, 5, 5, 0, 0, 0,\n",
            "        5, 5, 2, 3, 4, 2, 4, 2, 0, 5, 5, 1, 2, 4, 5, 0, 0, 5, 1, 0, 5, 5, 3, 3,\n",
            "        5, 5, 5, 4, 3, 5, 2, 5, 0, 5, 2, 5, 5, 5, 4, 5, 4, 4, 4, 5, 2, 4, 0, 5,\n",
            "        3, 4, 5, 5, 0, 0, 3, 5, 3, 1, 2, 2, 0, 4, 4, 0, 5, 3, 1, 5, 1, 3, 5, 5,\n",
            "        4, 2, 0, 1, 2, 5, 0, 5, 0, 2, 5, 2, 0, 0, 5, 0, 0, 5, 0, 4, 2, 0, 4, 2,\n",
            "        2, 2, 1, 0, 2, 5, 4, 0, 0, 4, 4, 2, 4, 5, 0, 4, 2, 5, 4, 2, 2, 0, 0, 0,\n",
            "        0, 4, 2, 0, 5, 5, 5, 0, 5, 0, 4, 4, 5, 5, 2, 2])\n",
            "tensor([5, 5, 0, 5, 0, 5, 0, 5, 2, 5, 5, 3, 5, 4, 4, 5, 5, 3, 0, 3, 3, 3, 5, 5,\n",
            "        0, 2, 5, 2, 5, 5, 2, 0, 4, 0, 5, 2, 2, 5, 2, 5, 1, 4, 2, 2, 5, 4, 0, 2,\n",
            "        5, 5, 5, 4, 1, 2, 2, 5, 5, 5, 4, 3, 4, 4, 4, 2, 0, 2, 3, 5, 0, 4, 3, 4,\n",
            "        0, 5, 2, 1, 5, 4, 2, 5, 5, 0, 1, 4, 2, 1, 5, 4, 0, 5, 0, 2, 2, 1, 0, 3,\n",
            "        3, 5, 5, 0, 0, 5, 0, 3, 4, 4, 4, 4, 5, 4, 5, 1, 5, 4, 5, 1, 1, 3, 5, 5,\n",
            "        5, 3, 0, 5, 2, 5, 5, 3, 0, 5, 2, 2, 4, 5, 5, 1, 3, 5, 5, 5, 4, 4, 4, 4,\n",
            "        4, 0, 4, 2, 2, 5, 5, 2, 3, 1, 2, 5, 4, 3, 2, 3, 5, 1, 4, 4, 5, 1, 5, 5,\n",
            "        5, 5, 0, 2, 5, 1, 0, 4, 2, 4, 4, 0, 5, 5, 3, 5, 3, 4, 5, 5, 2, 4, 4, 4,\n",
            "        5, 2, 2, 3, 0, 5, 1, 4, 5, 1, 3, 0, 4, 0, 4, 0, 2, 0, 4, 4, 0, 3, 5, 4,\n",
            "        5, 5, 0, 5, 5, 3, 5, 3, 0, 4, 5, 2, 4, 5, 2, 2, 0, 5, 0, 4, 4, 4, 5, 0,\n",
            "        5, 1, 5, 5, 4, 4, 2, 5, 2, 2, 2, 0, 4, 1, 5, 4])\n",
            "tensor([5, 4, 5, 1, 5, 3, 0, 0, 2, 2, 1, 0, 3, 1, 0, 0, 2, 5, 5, 0, 5, 0, 0, 3,\n",
            "        5, 5, 0, 0, 0, 5, 0, 0, 5, 4, 3, 3, 5, 1, 0, 2, 5, 1, 5, 2, 2, 0, 0, 2,\n",
            "        0, 1, 3, 0, 4, 1, 4, 5, 5, 5, 3, 0, 5, 5, 4, 0, 3, 2, 1, 0, 5, 5, 5, 3,\n",
            "        5, 3, 4, 5, 1, 4, 2, 1, 0, 2, 2, 1, 4, 4, 2, 3, 5, 4, 0, 1, 1, 2, 5, 2,\n",
            "        0, 0, 5, 2, 1, 4, 0, 2, 2, 3, 5, 5, 0, 5, 0, 2, 0, 2, 5, 4, 0, 5, 3, 1,\n",
            "        5, 5, 2, 1, 1, 4, 5, 5, 3, 4, 1, 2, 1, 5, 1, 2, 0, 2, 5, 0, 4, 4, 0, 3,\n",
            "        5, 0, 5, 0, 4, 0, 0, 0, 3, 3, 5, 0, 1, 0, 4, 3, 0, 1, 5, 0, 0, 3, 4, 5,\n",
            "        2, 3, 5, 1, 5, 4, 5, 5, 1, 1, 1, 5, 0, 0, 2, 4, 5, 3, 5, 4, 4, 2, 2, 2,\n",
            "        4, 2, 1, 1, 0, 2, 2, 5, 0, 2, 0, 2, 5, 5, 2, 5, 5, 2, 1, 4, 0, 4, 4, 0,\n",
            "        1, 0, 5, 1, 5, 0, 5, 2, 5, 5, 5, 4, 5, 2, 4, 0, 5, 5, 5, 5, 3, 0, 3, 5,\n",
            "        3, 5, 1, 0, 3, 3, 5, 2, 3, 2, 5, 0, 5, 3, 5, 5])\n",
            "tensor([3, 5, 5, 0, 2, 5, 2, 5, 0, 3, 4, 5, 2, 2, 3, 5, 0, 1, 3, 0, 5, 5, 3, 5,\n",
            "        5, 5, 5, 4, 2, 4, 5, 3, 2, 2, 2, 3, 4, 1, 5, 5, 2, 3, 4, 1, 1, 0, 1, 1,\n",
            "        4, 5, 5, 4, 3, 4, 4, 5, 4, 0, 4, 5, 5, 1, 0, 1, 2, 4, 5, 5, 1, 0, 4, 2,\n",
            "        3, 5, 4, 0, 3, 5, 1, 5, 1, 2, 1, 5, 5, 5, 2, 3, 5, 1, 1, 3, 2, 4, 5, 5,\n",
            "        5, 4, 0, 0, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 5, 5, 2, 3, 2, 1, 0, 4, 0, 0,\n",
            "        5, 5, 5, 4, 0, 0, 5, 5, 5, 2, 5, 5, 5, 1, 1, 5, 5, 0, 4, 1, 1, 5, 5, 4,\n",
            "        4, 1, 0, 4, 4, 2, 0, 4, 2, 4, 0, 1, 2, 2, 3, 5, 2, 1, 5, 0, 3, 2, 1, 2,\n",
            "        1, 2, 5, 2, 5, 5, 0, 2, 2, 4, 3, 5, 5, 0, 0, 2, 3, 5, 0, 5, 5, 2, 3, 5,\n",
            "        4, 2, 0, 5, 1, 4, 0, 3, 2, 5, 2, 4, 5, 2, 4, 5, 2, 3, 5, 0, 1, 1, 5, 5,\n",
            "        3, 5, 3, 1, 2, 1, 5, 0, 1, 5, 3, 4, 3, 2, 2, 5, 3, 5, 5, 2, 0, 2, 1, 2,\n",
            "        0, 3, 2, 1, 2, 2, 3, 5, 4, 1, 5, 0, 2, 5, 3, 3])\n",
            "tensor([3, 4, 3, 0, 0, 4, 5, 2, 1, 1, 1, 5, 1, 2, 3, 2, 0, 5, 0, 0, 4, 3, 2, 0,\n",
            "        1, 0, 4, 5, 0, 3, 0, 5, 5, 2, 5, 5, 1, 0, 5, 0, 0, 0, 4, 5, 4, 2, 2, 0,\n",
            "        5, 1, 5, 5, 2, 5, 0, 2, 5, 0, 1, 5, 3, 4, 5, 0, 4, 5, 5, 5, 1, 5, 4, 3,\n",
            "        5, 5, 5, 5, 1, 5, 3, 5, 0, 4, 4, 1, 4, 5, 2, 5, 5, 4, 5, 4, 3, 5, 5, 4,\n",
            "        0, 5, 5, 5, 5, 5, 3, 5, 1, 4, 5, 5, 1, 5, 4, 5, 5, 5, 1, 2, 5, 1, 0, 5,\n",
            "        4, 0, 2, 2, 5, 3, 3, 5, 4, 5, 5, 4, 2, 5, 2, 4, 0, 0, 0, 1, 2, 0, 5, 4,\n",
            "        2, 2, 5, 2, 4, 2, 2, 0, 5, 4, 4, 5, 2, 2, 4, 3, 4, 5, 2, 4, 0, 5, 5, 4,\n",
            "        5, 0, 5, 0, 5, 2, 5, 0, 4, 3, 1, 3, 5, 5, 2, 5, 0, 4, 5, 4, 5, 5, 4, 0,\n",
            "        5, 5, 5, 0, 5, 5, 4, 2, 2, 0, 3, 5, 4, 2, 0, 5, 3, 2, 1, 0, 2, 5, 0, 3,\n",
            "        1, 2, 3, 4, 0, 4, 3, 2, 3, 4, 0, 5, 5, 5, 5, 5, 5, 2, 4, 4, 5, 0, 5, 5,\n",
            "        2, 5, 4, 2, 3, 4, 0, 0, 3, 0, 5, 0, 5, 0, 3, 5])\n",
            "tensor([2, 2, 2, 5, 4, 0, 5, 0, 0, 2, 1, 5, 0, 3, 3, 4, 5, 5, 0, 5, 3, 5, 0, 5,\n",
            "        1, 5, 5, 0, 1, 3, 2, 4, 4, 2, 0, 4, 0, 0, 2, 1, 0, 4, 5, 2, 0, 2, 4, 4,\n",
            "        3, 2, 0, 5, 2, 5, 0, 0, 5, 5, 5, 0, 3, 5, 5, 4, 5, 2, 5, 5, 4, 4, 0, 5,\n",
            "        1, 3, 4, 5, 5, 3, 3, 4, 5, 5, 5, 5, 2, 5, 0, 5, 5, 0, 4, 0, 1, 4, 2, 1,\n",
            "        2, 5, 5, 5, 0, 4, 4, 0, 4, 3, 0, 5, 3, 3, 4, 1, 5, 2, 0, 5, 0, 5, 5, 4,\n",
            "        0, 2, 2, 5, 2, 2, 1, 5, 4, 2, 5, 0, 1, 5, 5, 0, 5, 1, 2, 5, 0, 4, 0, 5,\n",
            "        3, 4, 4, 4, 2, 0, 1, 5, 5, 1, 3, 0, 2, 5, 0, 5, 0, 3, 5, 5, 5, 4, 1, 2,\n",
            "        5, 0, 2, 0, 0, 4, 5, 2, 5, 3, 2, 2, 3, 3, 0, 5, 2, 2, 5, 5, 1, 2, 4, 0,\n",
            "        4, 4, 1, 5, 5, 2, 4, 0, 2, 2, 5, 4, 0, 5, 2, 0, 3, 5, 0, 5, 5, 4, 5, 2,\n",
            "        5, 1, 5, 1, 0, 5, 2, 5, 5, 5, 0, 0, 2, 1, 0, 5, 4, 2, 3, 5, 0, 5, 0, 5,\n",
            "        5, 2, 2, 4, 2, 0, 0, 1, 4, 4, 0, 5, 4, 5, 4, 0])\n",
            "tensor([2, 5, 5, 3, 0, 5, 5, 3, 5, 2, 0, 3, 5, 2, 3, 4, 2, 3, 3, 0, 2, 0, 5, 1,\n",
            "        5, 4, 3, 5, 4, 5, 1, 5, 1, 3, 1, 5, 5, 2, 0, 3, 2, 2, 4, 5, 2, 2, 4, 2,\n",
            "        4, 4, 0, 2, 5, 0, 5, 0, 2, 0, 1, 5, 5, 2, 5, 5, 1, 0, 5, 5, 4, 2, 5, 1,\n",
            "        1, 0, 3, 5, 0, 5, 4, 0, 5, 4, 2, 5, 1, 4, 0, 4, 4, 5, 2, 5, 0, 1, 1, 5,\n",
            "        0, 5, 2, 3, 5, 2, 4, 2, 0, 0, 1, 2, 0, 0, 4, 0, 1, 0, 5, 5, 5, 5, 2, 4,\n",
            "        5, 0, 0, 5, 5, 3, 2, 3, 5, 4, 5, 2, 5, 4, 3, 1, 2, 5, 5, 0, 0, 0, 0, 2,\n",
            "        5, 5, 1, 5, 1, 5, 2, 3, 0, 3, 5, 1, 5, 5, 0, 5, 3, 2, 2, 2, 3, 3, 2, 3,\n",
            "        5, 5, 5, 0, 0, 5, 1, 5, 5, 2, 0, 5, 0, 4, 5, 0, 3, 2, 0, 0, 1, 1, 4, 3,\n",
            "        4, 5, 3, 0, 4, 2, 4, 0, 1, 2, 5, 4, 5, 0, 5, 0, 5, 4, 2, 2, 0, 3, 5, 5,\n",
            "        2, 1, 0, 2, 1, 3, 5, 0, 5, 5, 4, 4, 5, 1, 5, 2, 4, 4, 5, 2, 3, 5, 4, 5,\n",
            "        0, 4, 1, 5, 2, 2, 4, 5, 5, 4, 4, 2, 5, 0, 1, 5])\n",
            "tensor([0, 5, 3, 5, 3, 1, 1, 5, 5, 0, 4, 0, 5, 1, 2, 0, 2, 1, 4, 4, 5, 5, 5, 3,\n",
            "        5, 5, 2, 0, 1, 2, 3, 3, 5, 0, 5, 5, 2, 3, 1, 4, 4, 2, 5, 4, 5, 2, 0, 2,\n",
            "        0, 5, 0, 5, 5, 5, 2, 3, 2, 5, 5, 5, 4, 0, 0, 5, 5, 5, 2, 5, 0, 3, 3, 5,\n",
            "        3, 3, 3, 1, 3, 1, 3, 0, 0, 1, 0, 2, 2, 0, 5, 4, 4, 5, 3, 4, 0, 0, 4, 5,\n",
            "        5, 3, 4, 5, 4, 0, 2, 1, 1, 0, 2, 5, 4, 1, 5, 5, 2, 1, 1, 5, 5, 1, 0, 5,\n",
            "        5, 5, 5, 0, 0, 5, 1, 5, 2, 1, 0, 2, 2, 0, 2, 0, 5, 4, 1, 4, 1, 4, 4, 1,\n",
            "        2, 4, 5, 3, 3, 5, 5, 0, 0, 4, 0, 0, 2, 4, 4, 2, 5, 1, 5, 5, 3, 5, 5, 5,\n",
            "        0, 0, 1, 4, 5, 3, 0, 4, 4, 2, 5, 5, 4, 0, 3, 5, 2, 2, 1, 1, 1, 5, 2, 5,\n",
            "        0, 5, 2, 3, 1, 4, 4, 4, 5, 2, 5, 3, 0, 0, 5, 3, 2, 5, 5, 5, 5, 5, 0, 0,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 0, 4, 4, 5, 2, 5, 5, 2, 4, 1, 5, 5, 5, 5, 3, 4,\n",
            "        5, 0, 5, 5, 3, 2, 2, 5, 0, 5, 5, 5, 5, 1, 3, 5])\n",
            "tensor([1, 5, 2, 5, 5, 0, 4, 4, 1, 3, 5, 0, 4, 5, 3, 1, 5, 4, 0, 5, 3, 1, 5, 2,\n",
            "        5, 0, 5, 4, 0, 5, 1, 5, 5, 2, 3, 1, 3, 0, 5, 3, 2, 1, 4, 5, 1, 0, 5, 5,\n",
            "        0, 4, 2, 5, 0, 4, 5, 3, 2, 5, 4, 1, 4, 5, 1, 5, 5, 3, 1, 5, 2, 2, 1, 2,\n",
            "        5, 3, 5, 5, 5, 4, 0, 4, 1, 4, 1, 0, 4, 5, 4, 2, 2, 2, 0, 5, 5, 4, 1, 5,\n",
            "        1, 2, 2, 5, 5, 3, 1, 2, 3, 2, 5, 4, 5, 5, 4, 5, 0, 0, 0, 5, 4, 5, 2, 5,\n",
            "        0, 1, 5, 5, 5, 0, 4, 5, 2, 1, 5, 2, 2, 1, 5, 0, 0, 1, 5, 1, 0, 2, 1, 3,\n",
            "        5, 0, 5, 0, 5, 5, 4, 5, 0, 2, 5, 5, 5, 0, 2, 0, 0, 5, 4, 2, 2, 5, 3, 1,\n",
            "        0, 4, 4, 5, 5, 0, 0, 4, 4, 2, 5, 5, 5, 1, 2, 3, 0, 3, 2, 5, 2, 1, 4, 3,\n",
            "        2, 2, 4, 5, 4, 0, 2, 0, 1, 2, 5, 4, 5, 0, 0, 2, 0, 3, 0, 5, 0, 3, 2, 4,\n",
            "        4, 3, 4, 3, 1, 5, 0, 3, 0, 5, 5, 4, 5, 5, 4, 3, 5, 2, 5, 3, 0, 0, 5, 0,\n",
            "        5, 0, 4, 4, 3, 2, 4, 2, 2, 5, 1, 3, 4, 2, 5, 3])\n",
            "tensor([3, 2, 0, 0, 5, 5, 0, 4, 3, 2, 1, 0, 5, 2, 4, 5, 4, 5, 5, 5, 1, 1, 1, 1,\n",
            "        5, 5, 2, 3, 1, 5, 0, 0, 4, 2, 0, 0, 4, 4, 1, 5, 3, 5, 0, 4, 4, 4, 5, 5,\n",
            "        5, 1, 4, 5, 4, 5, 2, 5, 2, 3, 4, 1, 2, 4, 2, 1, 2, 2, 2, 5, 1, 5, 3, 4,\n",
            "        5, 2, 5, 0, 0, 2, 4, 4, 4, 1, 5, 3, 2, 3, 5, 0, 0, 2, 0, 0, 2, 0, 4, 4,\n",
            "        4, 2, 4, 5, 3, 5, 5, 4, 5, 4, 5, 4, 2, 2, 5, 5, 0, 5, 3, 5, 4, 0, 1, 5,\n",
            "        5, 5, 4, 5, 4, 2, 4, 5, 5, 5, 5, 2, 5, 0, 5, 2, 2, 2, 5, 5, 5, 4, 2, 5,\n",
            "        5, 4, 0, 1, 3, 1, 2, 0, 1, 5, 3, 0, 5, 2, 2, 2, 4, 3, 4, 1, 1, 3, 5, 2,\n",
            "        5, 0, 4, 5, 4, 0, 1, 5, 4, 0, 5, 3, 0, 2, 5, 0, 4, 4, 5, 5, 3, 4, 0, 2,\n",
            "        2, 2, 4, 5, 5, 0, 2, 4, 4, 5, 2, 0, 0, 1, 3, 5, 5, 0, 3, 5, 5, 4, 3, 2,\n",
            "        4, 5, 3, 0, 4, 4, 0, 3, 5, 1, 5, 4, 2, 5, 5, 1, 1, 0, 2, 4, 0, 0, 4, 5,\n",
            "        5, 0, 3, 5, 4, 3, 0, 5, 5, 2, 5, 2, 0, 4, 0, 2])\n",
            "tensor([4, 5, 2, 3, 5, 1, 1, 0, 5, 2, 5, 5, 2, 0, 2, 2, 5, 0, 0, 0, 5, 1, 5, 0,\n",
            "        5, 0, 4, 0, 4, 2, 2, 0, 0, 5, 1, 5, 2, 4, 2, 5, 0, 5, 0, 0, 0, 0, 5, 5,\n",
            "        2, 4, 2, 2, 3, 4, 3, 2, 5, 3, 4, 5, 0, 4, 2, 5, 0, 5, 0, 3, 5, 0, 5, 2,\n",
            "        2, 4, 2, 5, 0, 5, 5, 5, 2, 2, 1, 5, 2, 0, 5, 4, 0, 5, 3, 2, 0, 5, 3, 1,\n",
            "        5, 5, 2, 4, 0, 2, 0, 3, 0, 4, 4, 4, 2, 5, 2, 1, 5, 5, 1, 5, 3, 4, 2, 4,\n",
            "        5, 5, 0, 5, 2, 5, 4, 0, 2, 0, 5, 4, 2, 0, 4, 3, 3, 4, 4, 5, 0, 5, 1, 5,\n",
            "        0, 2, 5, 2, 2, 5, 3, 5, 5, 5, 1, 0, 5, 1, 2, 2, 5, 3, 5, 5, 5, 5, 4, 3,\n",
            "        5, 3, 5, 2, 0, 3, 4, 2, 5, 4, 0, 0, 1, 4, 5, 5, 5, 5, 0, 1, 5, 0, 4, 2,\n",
            "        1, 5, 0, 1, 0, 2, 1, 5, 4, 5, 5, 2, 5, 5, 5, 3, 5, 2, 3, 2, 1, 1, 3, 1,\n",
            "        5, 5, 5, 1, 5, 4, 5, 5, 2, 5, 2, 4, 0, 5, 5, 2, 1, 5, 1, 0, 4, 0, 3, 2,\n",
            "        0, 5, 4, 5, 0, 4, 3, 5, 1, 4, 1, 5, 1, 0, 4, 5])\n",
            "tensor([5, 4, 4, 2, 1, 1, 5, 5, 2, 4, 2, 5, 3, 0, 1, 4, 5, 1, 0, 5, 4, 1, 5, 4,\n",
            "        2, 2, 1, 5, 3, 5, 5, 5, 4, 5, 4, 4, 2, 3, 2, 5, 0, 5, 2, 0, 4, 5, 4, 5,\n",
            "        5, 3, 4, 1, 2, 2, 2, 1, 0, 0, 2, 2, 0, 2, 4, 4, 5, 5, 2, 0, 4, 3, 1, 5,\n",
            "        1, 5, 5, 2, 5, 0, 5, 3, 0, 5, 5, 1, 4, 2, 1, 5, 4, 2, 5, 5, 5, 0, 1, 2,\n",
            "        0, 0, 3, 3, 5, 4, 4, 5, 2, 4, 5, 5, 2, 5, 5, 1, 4, 2, 3, 3, 5, 2, 5, 5,\n",
            "        4, 4, 3, 2, 2, 0, 0, 1, 5, 5, 5, 0, 2, 0, 4, 4, 5, 5, 3, 5, 5, 4, 1, 5,\n",
            "        5, 2, 2, 5, 2, 2, 0, 0, 2, 5, 5, 5, 5, 1, 2, 3, 5, 5, 2, 5, 2, 1, 5, 2,\n",
            "        5, 2, 2, 4, 5, 2, 5, 5, 5, 3, 2, 4, 0, 0, 0, 0, 2, 5, 5, 2, 4, 5, 5, 3,\n",
            "        0, 0, 3, 1, 0, 4, 5, 5, 4, 2, 0, 5, 0, 0, 2, 2, 5, 2, 5, 5, 5, 0, 3, 1,\n",
            "        5, 5, 4, 4, 2, 3, 2, 5, 5, 2, 0, 5, 2, 2, 3, 5, 1, 2, 4, 2, 2, 5, 2, 4,\n",
            "        0, 2, 3, 2, 2, 3, 3, 1, 4, 0, 0, 0, 1, 0, 3, 3])\n",
            "tensor([1, 5, 1, 4, 5, 5, 1, 1, 4, 2, 4, 5, 0, 5, 2, 3, 3, 2, 5, 4, 2, 3, 5, 5,\n",
            "        5, 5, 4, 5, 3, 4, 5, 4, 4, 2, 1, 4, 4, 4, 2, 4, 4, 0, 1, 5, 0, 3, 4, 3,\n",
            "        5, 0, 1, 5, 5, 2, 0, 2, 4, 5, 1, 4, 0, 5, 1, 5, 1, 3, 0, 1, 1, 3, 5, 5,\n",
            "        2, 4, 1, 5, 4, 5, 4, 0, 4, 4, 5, 3, 3, 5, 0, 0, 0, 3, 4, 5, 4, 1, 5, 5,\n",
            "        2, 4, 5, 2, 5, 4, 5, 4, 0, 2, 0, 1, 3, 3, 1, 5, 4, 5, 2, 2, 5, 5, 3, 3,\n",
            "        0, 0, 3, 3, 5, 5, 1, 5, 2, 1, 5, 5, 2, 2, 4, 5, 2, 3, 5, 5, 5, 0, 5, 5,\n",
            "        5, 2, 5, 5, 1, 5, 0, 5, 4, 5, 3, 4, 0, 2, 4, 4, 5, 5, 2, 4, 4, 5, 5, 5,\n",
            "        2, 3, 5, 4, 4, 3, 0, 3, 0, 0, 2, 5, 4, 3, 1, 4, 5, 0, 3, 5, 4, 0, 0, 3,\n",
            "        2, 5, 0, 5, 0, 5, 3, 3, 5, 3, 4, 3, 0, 1, 2, 0, 5, 0, 2, 3, 5, 3, 5, 0,\n",
            "        2, 2, 4, 5, 5, 0, 3, 2, 4, 5, 1, 5, 5, 5, 5, 5, 2, 0, 5, 1, 0, 3, 4, 5,\n",
            "        0, 5, 2, 5, 5, 5, 5, 0, 0, 1, 2, 1, 5, 4, 5, 0])\n",
            "tensor([5, 3, 0, 0, 1, 5, 2, 5, 1, 5, 5, 0, 4, 3, 5, 4, 1, 5, 1, 5, 5, 1, 5, 5,\n",
            "        3, 2, 4, 0, 5, 0, 3, 0, 0, 0, 0, 5, 5, 4, 5, 5, 3, 1, 5, 0, 2, 2, 2, 1,\n",
            "        5, 5, 1, 4, 0, 0, 5, 5, 3, 0, 4, 5, 3, 4, 4, 5, 2, 4, 4, 5, 4, 2, 3, 2,\n",
            "        0, 4, 5, 2, 4, 3, 0, 4, 5, 1, 1, 5, 0, 5, 5, 4, 4, 5, 0, 5, 5, 4, 5, 3,\n",
            "        1, 3, 2, 0, 1, 5, 3, 0, 5, 0, 5, 1, 4, 3, 4, 0, 4, 2, 1, 1, 2, 5, 0, 0,\n",
            "        3, 5, 4, 2, 2, 3, 5, 2, 0, 3, 1, 3, 0, 5, 5, 4, 3, 4, 4, 1, 1, 5, 5, 2,\n",
            "        2, 5, 2, 5, 5, 4, 4, 5, 5, 0, 0, 5, 5, 1, 1, 2, 5, 2, 5, 0, 2, 5, 3, 5,\n",
            "        5, 4, 5, 0, 5, 0, 5, 0, 2, 2, 5, 1, 3, 5, 2, 0, 2, 4, 5, 3, 0, 0, 0, 5,\n",
            "        1, 0, 5, 2, 0, 3, 4, 2, 4, 0, 1, 4, 5, 0, 5, 3, 5, 3, 5, 3, 3, 1, 5, 0,\n",
            "        0, 3, 5, 5, 1, 5, 3, 5, 4, 4, 1, 5, 3, 1, 3, 4, 2, 2, 3, 5, 4, 5, 5, 2,\n",
            "        2, 1, 1, 2, 2, 3, 5, 5, 2, 0, 2, 4, 4, 5, 0, 5])\n",
            "tensor([4, 0, 2, 5, 5, 5, 1, 4, 4, 5, 2, 0, 4, 1, 0, 5, 4, 5, 0, 5, 4, 5, 4, 2,\n",
            "        1, 5, 5, 2, 5, 3, 5, 5, 2, 5, 3, 5, 3, 5, 5, 2, 0, 0, 5, 5, 4, 5, 4, 1,\n",
            "        4, 5, 2, 4, 5, 0, 5, 3, 0, 5, 1, 1, 4, 1, 0, 3, 0, 5, 1, 0, 4, 1, 4, 4,\n",
            "        5, 2, 4, 4, 3, 4, 4, 0, 2, 2, 5, 4, 5, 4, 5, 4, 4, 4, 4, 1, 2, 3, 5, 3,\n",
            "        5, 5, 3, 1, 2, 4, 3, 3, 4, 5, 4, 2, 4, 0, 5, 4, 1, 4, 0, 0, 2, 5, 4, 1,\n",
            "        3, 2, 2, 5, 4, 3, 4, 1, 5, 3, 5, 1, 0, 3, 5, 0, 5, 1, 3, 5, 0, 1, 3, 4,\n",
            "        4, 5, 3, 5, 1, 4, 1, 2, 5, 0, 4, 5, 1, 0, 2, 1, 5, 4, 1, 2, 2, 4, 3, 2,\n",
            "        5, 4, 4, 5, 2, 1, 1, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 2, 0, 1, 0, 4, 1, 5,\n",
            "        0, 1, 5, 4, 4, 3, 2, 1, 0, 4, 1, 0, 4, 4, 2, 5, 4, 0, 0, 2, 4, 0, 1, 5,\n",
            "        0, 4, 5, 0, 2, 1, 2, 5, 5, 4, 5, 5, 4, 0, 5, 5, 4, 5, 5, 4, 5, 4, 4, 4,\n",
            "        5, 0, 0, 4, 5, 0, 5, 2, 5, 0, 5, 1, 2, 3, 2, 5])\n",
            "tensor([2, 3, 0, 5, 0, 5, 2, 4, 5, 1, 0, 2, 0, 5, 4, 5, 2, 5, 4, 5, 2, 3, 5, 1,\n",
            "        5, 0, 0, 2, 5, 3, 2, 4, 4, 1, 4, 5, 1, 5, 2, 2, 1, 5, 4, 0, 5, 3, 4, 2,\n",
            "        4, 1, 4, 2, 4, 5, 5, 0, 0, 0, 0, 2, 5, 0, 5, 2, 4, 4, 1, 4, 4, 4, 5, 2,\n",
            "        2, 2, 5, 4, 5, 3, 1, 5, 0, 5, 5, 5, 5, 5, 0, 3, 1, 3, 0, 5, 4, 1, 5, 5,\n",
            "        4, 5, 4, 5, 0, 0, 0, 5, 5, 3, 2, 4, 5, 2, 0, 5, 0, 4, 5, 5, 2, 5, 5, 1,\n",
            "        2, 2, 5, 5, 3, 5, 1, 0, 1, 4, 5, 5, 0, 3, 0, 5, 4, 2, 0, 5, 4, 0, 5, 4,\n",
            "        1, 5, 5, 3, 3, 5, 1, 5, 2, 5, 4, 1, 3, 2, 0, 5, 2, 2, 5, 4, 5, 1, 1, 5,\n",
            "        1, 0, 0, 4, 0, 0, 5, 5, 5, 2, 0, 2, 5, 1, 3, 2, 4, 5, 0, 2, 2, 5, 4, 0,\n",
            "        5, 3, 3, 5, 5, 0, 3, 2, 0, 5, 5, 4, 4, 1, 5, 4, 0, 5, 1, 0, 0, 5, 4, 5,\n",
            "        5, 4, 4, 2, 1, 0, 2, 4, 5, 4, 2, 4, 5, 1, 0, 5, 4, 0, 0, 0, 4, 4, 1, 5,\n",
            "        5, 5, 2, 5, 5, 2, 5, 3, 0, 2, 3, 4, 3, 4, 2, 5])\n",
            "tensor([5, 1, 4, 3, 5, 2, 2, 4, 4, 0, 5, 4, 2, 1, 5, 4, 5, 4, 2, 5, 2, 5, 5, 2,\n",
            "        3, 0, 5, 0, 5, 1, 5, 5, 1, 5, 1, 4, 5, 5, 5, 2, 5, 4, 0, 0, 5, 4, 5, 0,\n",
            "        2, 2, 3, 3, 2, 1, 1, 0, 1, 5, 0, 0, 0, 4, 0, 5, 0, 5, 5, 3, 5, 5, 4, 4,\n",
            "        5, 4, 5, 5, 1, 1, 3, 2, 5, 0, 4, 2, 5, 3, 5, 5, 0, 0, 4, 5, 5, 4, 2, 0,\n",
            "        5, 2, 2, 2, 3, 5, 4, 5, 4, 0, 4, 4, 2, 2, 5, 0, 5, 4, 5, 0, 0, 1, 5, 2,\n",
            "        0, 0, 2, 5, 5, 5, 0, 5, 3, 2, 0, 5, 3, 2, 2, 4, 4, 4, 4, 0, 5, 5, 2, 5,\n",
            "        5, 5, 0, 3, 4, 5, 4, 4, 5, 0, 1, 2, 5, 2, 0, 2, 5, 2, 3, 5, 5, 3, 2, 5,\n",
            "        0, 1, 5, 0, 1, 2, 4, 2, 0, 5, 3, 5, 0, 5, 5, 2, 4, 4, 4, 3, 3, 5, 1, 2,\n",
            "        4, 0, 1, 4, 0, 0, 4, 5, 5, 5, 0, 2, 5, 1, 5, 5, 0, 5, 5, 4, 3, 2, 0, 5,\n",
            "        5, 5, 3, 4, 5, 2, 5, 0, 1, 2, 1, 5, 3, 1, 2, 1, 0, 5, 5, 5, 5, 5, 1, 2,\n",
            "        2, 0, 5, 5, 5, 1, 5, 4, 5, 0, 1, 2, 1, 0, 5, 0])\n",
            "tensor([5, 2, 5, 2, 2, 3, 1, 4, 5, 3, 5, 2, 3, 5, 0, 3, 3, 0, 4, 4, 5, 0, 0, 0,\n",
            "        5, 5, 1, 2, 4, 0, 5, 4, 2, 0, 2, 4, 2, 3, 1, 1, 5, 0, 4, 3, 2, 5, 2, 5,\n",
            "        5, 5, 4, 1, 4, 2, 4, 5, 5, 2, 1, 0, 0, 2, 3, 1, 5, 4, 3, 1, 2, 0, 2, 0,\n",
            "        5, 5, 5, 4, 0, 1, 4, 4, 5, 0, 5, 1, 2, 2, 0, 3, 3, 5, 3, 5, 1, 2, 1, 4,\n",
            "        5, 5, 5, 0, 1, 5, 1, 5, 5, 5, 5, 1, 0, 1, 5, 5, 5, 5, 4, 1, 3, 0, 4, 0,\n",
            "        5, 1, 2, 1, 5, 3, 5, 4, 3, 3, 5, 5, 5, 5, 5, 3, 4, 5, 5, 4, 5, 5, 5, 1,\n",
            "        1, 5, 3, 0, 3, 5, 0, 5, 5, 4, 3, 5, 1, 5, 0, 5, 4, 0, 1, 5, 5, 0, 0, 4,\n",
            "        3, 1, 5, 5, 2, 3, 5, 4, 5, 3, 5, 0, 2, 5, 2, 1, 2, 4, 2, 5, 5, 0, 3, 5,\n",
            "        1, 2, 4, 5, 2, 2, 5, 1, 0, 0, 2, 4, 1, 5, 3, 0, 5, 4, 0, 0, 5, 4, 4, 4,\n",
            "        0, 5, 2, 2, 4, 2, 3, 3, 5, 0, 5, 1, 5, 4, 3, 1, 2, 5, 1, 0, 2, 5, 5, 1,\n",
            "        3, 4, 5, 5, 5, 3, 5, 4, 5, 0, 5, 5, 3, 3, 5, 3])\n",
            "tensor([1, 0, 0, 2, 5, 2, 5, 0, 4, 1, 5, 0, 2, 0, 5, 5, 5, 5, 4, 4, 1, 5, 5, 2,\n",
            "        4, 3, 0, 4, 0, 0, 3, 4, 4, 2, 4, 0, 2, 5, 5, 4, 5, 0, 5, 4, 3, 2, 3, 5,\n",
            "        4, 5, 5, 5, 5, 5, 5, 1, 3, 0, 2, 4, 2, 0, 0, 5, 2, 5, 1, 0, 5, 3, 5, 4,\n",
            "        0, 0, 3, 5, 3, 5, 5, 0, 5, 3, 0, 0, 0, 5, 0, 4, 2, 1, 2, 0, 4, 5, 2, 0,\n",
            "        5, 4, 2, 5, 0, 5, 0, 5, 2, 2, 5, 5, 5, 5, 5, 3, 4, 1, 4, 5, 0, 1, 5, 3,\n",
            "        3, 4, 5, 3, 5, 0, 2, 5, 4, 2, 2, 3, 5, 3, 0, 0, 1, 5, 5, 0, 2, 2, 1, 1,\n",
            "        3, 4, 2, 5, 2, 1, 5, 2, 0, 2, 4, 5, 2, 2, 2, 0, 5, 3, 2, 2, 3, 5, 2, 2,\n",
            "        3, 5, 2, 4, 5, 5, 4, 0, 1, 4, 4, 3, 5, 5, 1, 5, 5, 5, 1, 1, 2, 1, 0, 1,\n",
            "        2, 1, 2, 5, 2, 4, 2, 5, 0, 5, 3, 0, 1, 3, 2, 5, 3, 2, 1, 5, 4, 2, 2, 0,\n",
            "        2, 2, 3, 5, 5, 3, 1, 0, 2, 2, 5, 5, 1, 3, 3, 5, 1, 0, 0, 3, 5, 0, 4, 5,\n",
            "        5, 3, 1, 4, 5, 4, 5, 2, 5, 0, 0, 2, 3, 5, 2, 2])\n",
            "tensor([3, 2, 5, 3, 1, 5, 0, 2, 4, 3, 2, 0, 1, 5, 1, 0, 2, 3, 4, 5, 5, 5, 1, 5,\n",
            "        5, 5, 3, 5, 4, 5, 4, 0, 4, 5, 5, 5, 1, 4, 5, 5, 5, 0, 0, 5, 1, 4, 0, 4,\n",
            "        5, 1, 3, 0, 3, 5, 0, 0, 5, 0, 2, 5, 0, 2, 4, 0, 5, 2, 5, 4, 4, 5, 1, 2,\n",
            "        1, 5, 2, 4, 5, 2, 5, 5, 3, 4, 0, 3, 5, 5, 2, 3, 5, 2, 5, 1, 5, 1, 5, 1,\n",
            "        5, 0, 4, 1, 2, 4, 0, 5, 1, 0, 5, 1, 1, 1, 3, 5, 2, 2, 1, 2, 4, 4, 5, 2,\n",
            "        2, 2, 5, 4, 0, 0, 4, 3, 3, 4, 5, 2, 5, 4, 2, 3, 4, 4, 5, 0, 4, 4, 5, 2,\n",
            "        2, 5, 2, 5, 5, 2, 4, 4, 0, 4, 4, 2, 2, 5, 2, 5, 0, 5, 0, 0, 5, 5, 5, 4,\n",
            "        5, 4, 2, 3, 2, 3, 2, 5, 2, 2, 0, 5, 0, 2, 4, 5, 2, 0, 0, 5, 5, 2, 4, 5,\n",
            "        2, 4, 5, 5, 5, 1, 5, 1, 3, 0, 5, 0, 4, 1, 5, 1, 5, 3, 0, 4, 1, 0, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 0, 0, 4, 5, 4, 5, 5, 0, 2, 5, 2, 4, 5, 4, 3, 3, 3, 5,\n",
            "        5, 4, 4, 5, 4, 4, 5, 3, 4, 5, 0, 5, 0, 2, 2, 0])\n",
            "tensor([3, 4, 5, 2, 5, 4, 4, 5, 5, 2, 5, 5, 2, 2, 3, 2, 0, 5, 4, 1, 4, 5, 5, 2,\n",
            "        5, 5, 3, 2, 4, 3, 5, 1, 1, 5, 3, 3, 4, 3, 5, 5, 4, 0, 5, 5, 1, 2, 0, 5,\n",
            "        5, 1, 5, 0, 4, 2, 0, 0, 4, 4, 4, 4, 5, 2, 5, 5, 4, 5, 5, 2, 5, 4, 4, 5,\n",
            "        1, 0, 0, 0, 1, 2, 5, 5, 1, 3, 5, 5, 5, 0, 5, 1, 2, 0, 4, 5, 4, 3, 5, 5,\n",
            "        3, 0, 5, 5, 4, 3, 0, 5, 0, 2, 1, 3, 5, 2, 5, 2, 3, 5, 5, 5, 5, 5, 3, 4,\n",
            "        0, 1, 5, 5, 4, 1, 3, 0, 4, 4, 4, 3, 5, 5, 5, 0, 5, 2, 5, 2, 0, 1, 4, 5,\n",
            "        3, 0, 4, 5, 2, 4, 4, 3, 4, 4, 5, 0, 2, 3, 5, 4, 5, 2, 5, 5, 4, 0, 4, 2,\n",
            "        2, 2, 5, 5, 1, 0, 2, 3, 0, 0, 5, 1, 3, 5, 2, 4, 0, 2, 2, 5, 5, 5, 5, 5,\n",
            "        5, 2, 5, 3, 5, 2, 5, 5, 5, 2, 1, 2, 4, 0, 0, 2, 0, 3, 3, 4, 3, 0, 5, 5,\n",
            "        2, 2, 3, 4, 0, 0, 5, 2, 3, 0, 5, 4, 2, 4, 5, 5, 3, 4, 3, 5, 5, 0, 2, 0,\n",
            "        4, 2, 5, 5, 2, 1, 5, 1, 5, 2, 5, 4, 1, 5, 5, 5])\n",
            "tensor([4, 5, 5, 1, 4, 0, 5, 0, 5, 0, 4, 5, 4, 5, 3, 5, 0, 3, 5, 4, 5, 3, 0, 5,\n",
            "        4, 1, 0, 0, 5, 5, 4, 5, 0, 2, 2, 0, 5, 5, 4, 5, 3, 0, 4, 1, 5, 1, 5, 1,\n",
            "        2, 0, 5, 2, 5, 2, 0, 4, 5, 5, 2, 0, 5, 5, 0, 0, 3, 5, 2, 1, 4, 5, 5, 5,\n",
            "        4, 4, 5, 5, 0, 1, 5, 5, 5, 4, 5, 5, 2, 5, 1, 5, 1, 1, 5, 3, 3, 2, 2, 0,\n",
            "        4, 2, 2, 5, 5, 5, 0, 3, 4, 5, 5, 1, 5, 5, 2, 3, 1, 2, 4, 4, 5, 1, 5, 0,\n",
            "        0, 2, 0, 2, 0, 2, 5, 0, 3, 1, 5, 1, 1, 5, 2, 5, 5, 5, 5, 5, 1, 2, 2, 5,\n",
            "        4, 4, 4, 0, 0, 0, 2, 5, 1, 4, 0, 5, 5, 5, 5, 0, 3, 5, 2, 3, 5, 5, 5, 0,\n",
            "        1, 5, 4, 0, 4, 4, 3, 4, 3, 5, 5, 3, 2, 5, 3, 5, 1, 1, 1, 5, 5, 3, 4, 0,\n",
            "        5, 4, 5, 2, 5, 0, 0, 5, 3, 0, 4, 4, 4, 0, 5, 3, 5, 2, 5, 4, 0, 2, 2, 5,\n",
            "        0, 5, 4, 1, 0, 5, 5, 4, 5, 5, 0, 0, 4, 2, 4, 5, 5, 5, 4, 1, 5, 0, 5, 5,\n",
            "        1, 5, 5, 3, 3, 4, 3, 0, 4, 5, 0, 0, 1, 1, 5, 5])\n",
            "tensor([5, 3, 5, 2, 4, 3, 5, 3, 2, 5, 1, 2, 4, 3, 0, 0, 5, 0, 5, 5, 4, 5, 3, 1,\n",
            "        5, 2, 2, 0, 0, 2, 4, 1, 1, 1, 0, 2, 5, 0, 1, 2, 1, 0, 5, 5, 5, 5, 0, 5,\n",
            "        5, 1, 4, 5, 2, 2, 5, 5, 0, 5, 5, 0, 0, 2, 5, 2, 0, 5, 0, 2, 5, 1, 2, 0,\n",
            "        1, 5, 0, 0, 1, 5, 2, 3, 3, 0, 2, 5, 2, 5, 1, 3, 2, 3, 0, 4, 3, 2, 5, 0,\n",
            "        0, 5, 0, 5, 3, 4, 5, 1, 3, 0, 0, 0, 5, 1, 4, 2, 4, 4, 3, 0, 5, 2, 0, 1,\n",
            "        0, 1, 0, 1, 5, 2, 0, 4, 4, 3, 5, 3, 5, 4, 5, 1, 5, 2, 4, 1, 1, 1, 5, 2,\n",
            "        2, 4, 2, 5, 3, 3, 0, 4, 4, 0, 2, 5, 3, 5, 5, 4, 2, 5, 0, 5, 3, 3, 2, 2,\n",
            "        2, 3, 5, 3, 5, 0, 1, 1, 5, 2, 0, 5, 4, 5, 5, 5, 5, 4, 4, 3, 5, 5, 5, 5,\n",
            "        0, 4, 4, 5, 1, 4, 1, 5, 0, 3, 5, 4, 0, 0, 5, 5, 1, 4, 2, 5, 4, 3, 4, 5,\n",
            "        2, 3, 3, 4, 5, 0, 5, 0, 5, 5, 4, 0, 0, 0, 5, 5, 5, 5, 3, 2, 2, 2, 3, 0,\n",
            "        1, 4, 5, 5, 0, 4, 4, 4, 5, 5, 1, 1, 0, 5, 5, 5])\n",
            "tensor([2, 4, 5, 2, 5, 3, 1, 0, 5, 3, 2, 2, 3, 5, 0, 0, 2, 5, 5, 1, 5, 5, 2, 5,\n",
            "        5, 4, 3, 0, 4, 5, 1, 0, 5, 2, 0, 5, 5, 0, 5, 2, 0, 4, 3, 0, 1, 1, 4, 5,\n",
            "        2, 5, 1, 0, 0, 5, 4, 4, 4, 4, 0, 5, 1, 1, 5, 0, 3, 5, 0, 4, 5, 4, 1, 0,\n",
            "        2, 1, 1, 5, 2, 5, 4, 5, 0, 0, 5, 1, 3, 5, 2, 5, 0, 5, 5, 2, 2, 2, 5, 2,\n",
            "        0, 0, 5, 2, 5, 1, 4, 0, 5, 5, 4, 0, 4, 5, 0, 2, 4, 4, 4, 4, 5, 3, 2, 5,\n",
            "        0, 2, 2, 5, 3, 5, 5, 3, 5, 1, 4, 2, 0, 1, 5, 2, 0, 3, 1, 5, 1, 5, 3, 5,\n",
            "        0, 3, 5, 3, 3, 5, 5, 3, 0, 1, 0, 5, 2, 1, 5, 4, 5, 5, 3, 5, 3, 1, 3, 1,\n",
            "        4, 3, 2, 2, 5, 4, 3, 5, 0, 5, 4, 4, 4, 3, 4, 3, 0, 3, 0, 5, 5, 2, 1, 2,\n",
            "        5, 3, 4, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 5, 2, 3,\n",
            "        5, 0, 5, 4, 5, 5, 1, 2, 2, 5, 2, 5, 0, 4, 0, 2, 5, 0, 5, 5, 5, 4, 0, 4,\n",
            "        0, 3, 5, 5, 5, 2, 2, 3, 2, 5, 0, 2, 4, 1, 1, 2])\n",
            "tensor([5, 4, 5, 0, 5, 5, 2, 0, 2, 5, 0, 0, 0, 5, 2, 2, 3, 5, 5, 1, 1, 5, 4, 4,\n",
            "        4, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 5, 2, 2, 2, 2, 5, 5, 5, 5,\n",
            "        0, 5, 2, 5, 1, 2, 5, 5, 4, 0, 5, 0, 5, 1, 5, 5, 2, 2, 3, 5, 5, 3, 5, 1,\n",
            "        0, 5, 5, 5, 3, 4, 4, 4, 5, 5, 0, 2, 2, 3, 4, 1, 0, 4, 2, 2, 2, 4, 4, 4,\n",
            "        0, 4, 5, 1, 2, 2, 5, 0, 2, 5, 5, 0, 5, 5, 5, 2, 1, 5, 4, 1, 3, 2, 5, 5,\n",
            "        3, 0, 5, 2, 4, 5, 3, 1, 5, 5, 0, 4, 2, 5, 4, 0, 0, 2, 0, 4, 0, 2, 4, 0,\n",
            "        2, 4, 3, 3, 3, 4, 4, 2, 2, 5, 5, 3, 3, 3, 5, 5, 5, 0, 5, 5, 2, 2, 4, 3,\n",
            "        5, 0, 2, 5, 5, 5, 0, 5, 1, 1, 4, 5, 4, 2, 0, 1, 2, 2, 5, 2, 1, 2, 5, 5,\n",
            "        0, 3, 3, 0, 0, 1, 5, 1, 1, 0, 5, 2, 4, 2, 0, 0, 4, 1, 2, 0, 5, 5, 3, 2,\n",
            "        1, 0, 0, 3, 0, 5, 5, 0, 3, 5, 2, 0, 5, 5, 5, 5, 5, 5, 5, 2, 1, 0, 4, 2,\n",
            "        3, 5, 1, 2, 1, 4, 5, 5, 5, 3, 2, 2, 2, 5, 0, 3])\n",
            "tensor([3, 3, 3, 3, 0, 0, 5, 0, 4, 5, 1, 5, 0, 1, 0, 2, 2, 5, 4, 1, 2, 2, 3, 3,\n",
            "        2, 4, 3, 5, 3, 2, 4, 0, 1, 3, 3, 4, 5, 5, 3, 2, 1, 5, 5, 5, 2, 4, 2, 5,\n",
            "        2, 5, 4, 0, 3, 5, 5, 4, 5, 2, 2, 5, 1, 5, 0, 2, 4, 0, 4, 3, 2, 0, 1, 3,\n",
            "        4, 0, 5, 0, 3, 0, 5, 5, 4, 3, 5, 3, 5, 5, 1, 4, 5, 2, 2, 1, 2, 0, 4, 5,\n",
            "        2, 5, 5, 4, 3, 5, 3, 2, 0, 5, 4, 2, 5, 4, 2, 0, 5, 5, 0, 2, 1, 0, 3, 4,\n",
            "        5, 5, 4, 4, 5, 0, 5, 0, 3, 2, 2, 1, 5, 2, 3, 1, 5, 3, 1, 5, 3, 5, 1, 2,\n",
            "        5, 4, 2, 5, 1, 1, 4, 4, 0, 5, 2, 0, 5, 2, 1, 1, 3, 1, 4, 4, 4, 5, 0, 4,\n",
            "        2, 1, 5, 0, 5, 5, 4, 4, 3, 5, 5, 5, 4, 1, 3, 3, 1, 4, 2, 3, 0, 1, 2, 2,\n",
            "        3, 4, 2, 2, 3, 5, 5, 4, 1, 5, 0, 4, 4, 5, 5, 5, 3, 5, 2, 3, 1, 1, 0, 3,\n",
            "        0, 5, 0, 2, 4, 5, 3, 4, 0, 2, 1, 1, 4, 4, 5, 2, 5, 4, 1, 4, 1, 5, 4, 2,\n",
            "        0, 0, 5, 4, 0, 2, 3, 5, 5, 0, 2, 1, 1, 5, 4, 3])\n",
            "tensor([4, 5, 2, 1, 4, 3, 4, 1, 0, 4, 0, 0, 3, 2, 3, 5, 4, 0, 2, 5, 5, 5, 1, 5,\n",
            "        2, 0, 5, 1, 4, 1, 2, 0, 2, 4, 5, 1, 3, 0, 2, 1, 2, 2, 3, 2, 0, 5, 5, 0,\n",
            "        5, 5, 5, 2, 0, 1, 2, 3, 1, 5, 2, 5, 5, 4, 2, 5, 5, 5, 4, 4, 0, 5, 4, 5,\n",
            "        5, 5, 3, 2, 5, 4, 5, 5, 3, 1, 5, 0, 5, 2, 3, 5, 2, 3, 2, 2, 5, 5, 2, 0,\n",
            "        2, 2, 0, 0, 3, 5, 5, 3, 4, 0, 0, 4, 5, 4, 0, 0, 5, 5, 3, 4, 1, 2, 4, 0,\n",
            "        1, 4, 5, 5, 2, 4, 0, 3, 5, 4, 1, 5, 3, 1, 5, 5, 2, 4, 1, 3, 5, 0, 4, 3,\n",
            "        0, 2, 1, 4, 0, 5, 0, 2, 5, 5, 2, 0, 2, 2, 0, 2, 2, 5, 0, 1, 5, 4, 5, 5,\n",
            "        0, 4, 5, 3, 5, 1, 3, 5, 2, 0, 5, 0, 4, 5, 1, 3, 2, 4, 1, 0, 2, 5, 5, 4,\n",
            "        5, 0, 0, 2, 2, 4, 2, 4, 1, 5, 5, 0, 1, 1, 0, 3, 5, 5, 2, 5, 5, 4, 5, 2,\n",
            "        1, 0, 1, 5, 1, 2, 3, 5, 4, 4, 4, 5, 5, 5, 0, 2, 5, 5, 3, 3, 5, 2, 5, 2,\n",
            "        5, 5, 4, 1, 1, 5, 1, 5, 5, 0, 1, 1, 4, 2, 4, 5])\n",
            "tensor([4, 0, 4, 3, 3, 5, 2, 5, 5, 2, 0, 5, 5, 2, 5, 4, 4, 1, 5, 4, 4, 4, 0, 4,\n",
            "        5, 5, 1, 4, 0, 5, 4, 0, 3, 2, 2, 4, 5, 4, 2, 1, 5, 0, 2, 4, 5, 0, 0, 2,\n",
            "        5, 4, 2, 1, 4, 0, 5, 1, 3, 4, 5, 3, 5, 5, 0, 5, 2, 0, 0, 4, 5, 1, 4, 4,\n",
            "        0, 3, 5, 4, 0, 5, 2, 0, 4, 2, 3, 4, 5, 4, 3, 3, 0, 5, 3, 3, 2, 5, 2, 1,\n",
            "        5, 4, 5, 5, 5, 4, 5, 4, 4, 5, 3, 5, 0, 2, 3, 5, 0, 5, 1, 2, 1, 3, 5, 5,\n",
            "        0, 4, 4, 2, 3, 2, 4, 4, 0, 4, 0, 0, 5, 3, 0, 2, 3, 5, 5, 5, 1, 3, 0, 5,\n",
            "        5, 1, 5, 5, 5, 3, 0, 4, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5, 0, 4, 0, 0, 3,\n",
            "        2, 0, 5, 3, 4, 5, 3, 2, 0, 4, 4, 0, 5, 2, 5, 5, 5, 0, 3, 0, 1, 2, 2, 5,\n",
            "        0, 2, 5, 5, 3, 5, 0, 0, 5, 4, 5, 0, 3, 5, 3, 5, 1, 2, 3, 0, 5, 3, 4, 5,\n",
            "        0, 5, 0, 4, 4, 0, 1, 0, 0, 4, 0, 2, 4, 3, 0, 0, 2, 1, 1, 1, 5, 1, 5, 4,\n",
            "        3, 3, 3, 0, 3, 3, 3, 4, 5, 3, 0, 1, 5, 4, 5, 3])\n",
            "tensor([0, 0, 4, 5, 5, 4, 3, 4, 4, 2, 5, 2, 5, 0, 2, 2, 4, 4, 3, 4, 4, 5, 0, 5,\n",
            "        1, 5, 2, 2, 5, 0, 5, 0, 0, 2, 3, 1, 4, 4, 4, 1, 1, 0, 0, 5, 3, 2, 5, 0,\n",
            "        5, 4, 5, 2, 0, 2, 2, 4, 4, 2, 0, 5, 0, 5, 5, 0, 2, 4, 4, 4, 4, 0, 4, 0,\n",
            "        1, 3, 5, 4, 5, 2, 5, 5, 0, 2, 5, 2, 0, 0, 0, 4, 4, 5, 4, 4, 0, 0, 0, 4,\n",
            "        4, 0, 5, 3, 0, 3, 0, 5, 4, 5, 3, 1, 5, 2, 2, 5, 3, 1, 5, 2, 1, 5, 5, 5,\n",
            "        3, 0, 0, 5, 4, 3, 3, 5, 0, 3, 4, 5, 1, 0, 1, 4, 3, 4, 2, 4, 0, 0, 4, 4,\n",
            "        4, 2, 3, 5, 5, 5, 1, 5, 3, 1, 4, 0, 4, 1, 1, 4, 0, 5, 5, 3, 4, 0, 5, 1,\n",
            "        2, 2, 5, 0, 5, 0, 5, 3, 3, 1, 5, 5, 3, 1, 4, 4, 4, 2, 2, 0, 1, 3, 4, 4,\n",
            "        0, 4, 1, 5, 3, 5, 4, 5, 5, 2, 4, 5, 1, 0, 5, 5, 0, 4, 3, 2, 3, 5, 5, 3,\n",
            "        0, 0, 5, 5, 0, 4, 2, 3, 0, 5, 0, 0, 0, 0, 5, 5, 5, 4, 5, 4, 4, 2, 5, 5,\n",
            "        0, 2, 3, 0, 5, 3, 3, 2, 5, 5, 0, 2, 2, 4, 0, 5])\n",
            "tensor([5, 5, 4, 5, 5, 5, 1, 5, 2, 5, 2, 4, 5, 3, 4, 4, 0, 4, 5, 5, 3, 2, 4, 4,\n",
            "        4, 5, 1, 4, 2, 5, 2, 0, 0, 4, 5, 0, 5, 5, 4, 5, 1, 2, 4, 2, 5, 1, 5, 2,\n",
            "        4, 2, 2, 5, 5, 5, 2, 0, 2, 5, 4, 4, 2, 5, 2, 5, 2, 5, 3, 4, 0, 5, 5, 0,\n",
            "        5, 5, 5, 4, 5, 2, 1, 3, 3, 1, 2, 5, 5, 0, 4, 3, 5, 1, 5, 0, 5, 4, 3, 5,\n",
            "        0, 3, 3, 0, 5, 5, 5, 0, 1, 0, 5, 4, 5, 0, 0, 3, 4, 2, 2, 2, 5, 5, 4, 5,\n",
            "        4, 5, 4, 3, 5, 5, 5, 5, 5, 3, 0, 2, 2, 5, 1, 2, 4, 4, 5, 4, 2, 4, 3, 3,\n",
            "        5, 5, 0, 5, 2, 5, 1, 1, 2, 0, 2, 0, 0, 2, 2, 2, 1, 5, 0, 5, 4, 5, 4, 5,\n",
            "        2, 0, 4, 0, 5, 4, 5, 1, 4, 5, 5, 5, 2, 0, 0, 3, 5, 2, 0, 4, 5, 0, 5, 1,\n",
            "        5, 0, 0, 5, 5, 2, 5, 4, 5, 1, 2, 5, 0, 2, 4, 0, 4, 1, 5, 4, 5, 4, 5, 2,\n",
            "        0, 4, 3, 4, 5, 3, 5, 5, 5, 1, 5, 0, 5, 5, 4, 1, 5, 1, 4, 0, 4, 5, 5, 4,\n",
            "        1, 3, 5, 4, 3, 5, 1, 0, 2, 5, 2, 5, 4, 5, 5, 1])\n",
            "tensor([5, 5, 3, 3, 4, 4, 5, 3, 5, 0, 4, 2, 5, 2, 0, 0, 1, 0, 2, 5, 3, 1, 5, 5,\n",
            "        5, 5, 4, 4, 2, 2, 4, 2, 0, 0, 3, 3, 1, 5, 5, 5, 4, 5, 3, 5, 0, 0, 4, 0,\n",
            "        3, 4, 4, 3, 5, 2, 4, 1, 0, 1, 1, 5, 5, 4, 5, 2, 3, 5, 3, 0, 4, 5, 5, 3,\n",
            "        5, 1, 0, 3, 5, 5, 5, 0, 5, 3, 0, 3, 0, 3, 0, 5, 0, 4, 0, 2, 5, 4, 2, 5,\n",
            "        5, 0, 5, 3, 5, 0, 0, 1, 5, 5, 4, 0, 5, 5, 5, 2, 3, 5, 1, 3, 3, 5, 5, 0,\n",
            "        5, 4, 2, 2, 0, 1, 1, 4, 0, 0, 5, 2, 0, 1, 3, 1, 2, 0, 2, 3, 5, 2, 5, 3,\n",
            "        0, 5, 3, 5, 3, 3, 3, 3, 2, 3, 4, 2, 5, 2, 4, 5, 3, 1, 2, 4, 0, 1, 3, 4,\n",
            "        1, 2, 5, 5, 5, 2, 1, 2, 4, 2, 0, 5, 5, 3, 3, 2, 5, 4, 5, 0, 5, 2, 0, 5,\n",
            "        5, 5, 0, 1, 2, 3, 1, 2, 3, 5, 5, 3, 3, 5, 1, 2, 5, 1, 4, 1, 2, 0, 4, 5,\n",
            "        4, 5, 4, 5, 0, 1, 5, 0, 3, 5, 5, 2, 5, 1, 0, 2, 5, 3, 1, 4, 2, 0, 0, 3,\n",
            "        3, 1, 5, 5, 5, 1, 1, 3, 5, 0, 0, 2, 4, 5, 3, 0])\n",
            "tensor([5, 0, 0, 4, 0, 1, 2, 5, 2, 4, 0, 5, 5, 5, 4, 2, 5, 2, 5, 4, 2, 5, 3, 1,\n",
            "        3, 5, 5, 5, 5, 4, 2, 0, 2, 5, 3, 3, 2, 4, 4, 5, 4, 4, 1, 0, 5, 4, 3, 2,\n",
            "        5, 2, 2, 4, 3, 0, 5, 2, 0, 5, 5, 3, 3, 3, 3, 4, 2, 5, 0, 1, 4, 4, 5, 0,\n",
            "        5, 5, 5, 3, 4, 5, 1, 5, 2, 3, 3, 5, 4, 0, 3, 3, 5, 4, 1, 3, 3, 5, 0, 5,\n",
            "        3, 0, 1, 1, 4, 5, 3, 5, 2, 5, 5, 0, 5, 0, 1, 4, 2, 4, 2, 4, 3, 4, 0, 5,\n",
            "        5, 5, 0, 5, 5, 0, 1, 5, 3, 5, 5, 0, 2, 5, 4, 1, 4, 5, 0, 4, 1, 4, 2, 1,\n",
            "        3, 1, 2, 0, 5, 0, 4, 5, 2, 5, 2, 2, 0, 0, 5, 2, 2, 0, 0, 3, 2, 2, 0, 4,\n",
            "        4, 0, 1, 5, 5, 5, 2, 2, 3, 5, 4, 0, 5, 5, 4, 2, 2, 0, 1, 3, 0, 0, 5, 4,\n",
            "        1, 3, 5, 3, 2, 1, 0, 4, 5, 4, 0, 5, 2, 4, 2, 5, 5, 5, 1, 5, 3, 2, 0, 5,\n",
            "        0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 2, 2, 0, 0, 0, 5, 5, 5, 5, 3, 5, 2, 5, 3,\n",
            "        5, 5, 4, 0, 2, 3, 5, 1, 5, 1, 0, 4, 3, 1, 2, 5])\n",
            "tensor([1, 5, 4, 5, 3, 0, 2, 0, 2, 2, 2, 3, 0, 5, 3, 5, 0, 5, 4, 5, 2, 2, 1, 2,\n",
            "        3, 2, 4, 4, 0, 2, 1, 1, 0, 5, 5, 3, 1, 5, 3, 0, 2, 1, 1, 1, 5, 3, 3, 5,\n",
            "        5, 3, 3, 2, 5, 3, 3, 2, 2, 2, 4, 5, 3, 0, 2, 1, 0, 0, 0, 4, 2, 1, 0, 5,\n",
            "        0, 1, 5, 3, 4, 0, 5, 5, 5, 4, 3, 0, 5, 5, 1, 2, 5, 0, 2, 0, 0, 0, 5, 0,\n",
            "        5, 4, 0, 2, 5, 5, 5, 3, 2, 1, 3, 3, 1, 2, 1, 5, 2, 3, 0, 1, 0, 3, 4, 2,\n",
            "        5, 0, 5, 0, 4, 0, 1, 2, 5, 5, 4, 3, 1, 0, 0, 5, 2, 3, 5, 5, 4, 5, 0, 0,\n",
            "        4, 5, 3, 5, 3, 5, 0, 3, 2, 0, 4, 0, 3, 0, 5, 0, 4, 3, 2, 3, 5, 5, 5, 0,\n",
            "        0, 5, 5, 5, 5, 5, 5, 3, 0, 4, 5, 5, 3, 1, 5, 5, 5, 1, 5, 5, 4, 4, 2, 5,\n",
            "        0, 4, 0, 5, 5, 2, 0, 0, 2, 3, 4, 4, 5, 5, 1, 5, 5, 5, 2, 5, 5, 5, 0, 5,\n",
            "        2, 2, 5, 4, 0, 5, 3, 5, 2, 5, 5, 3, 1, 5, 5, 5, 3, 0, 5, 1, 5, 5, 2, 3,\n",
            "        4, 5, 2, 5, 5, 5, 5, 4, 5, 5, 5, 3, 5, 5, 3, 0])\n",
            "tensor([4, 4, 0, 5, 4, 2, 1, 5, 5, 3, 0, 0, 5, 4, 2, 1, 0, 5, 2, 2, 5, 4, 5, 3,\n",
            "        4, 5, 0, 5, 4, 5, 1, 5, 0, 2, 4, 2, 5, 0, 4, 2, 5, 0, 4, 2, 0, 2, 5, 0,\n",
            "        5, 5, 3, 4, 1, 5, 2, 0, 5, 5, 1, 1, 5, 0, 4, 2, 3, 5, 1, 3, 4, 3, 5, 0,\n",
            "        5, 0, 2, 2, 3, 5, 1, 4, 3, 5, 0, 4, 0, 0, 4, 3, 0, 1, 5, 2, 4, 5, 5, 4,\n",
            "        2, 0, 5, 0, 3, 4, 5, 5, 5, 0, 4, 5, 5, 5, 4, 0, 4, 1, 3, 2, 2, 2, 2, 3,\n",
            "        1, 5, 4, 5, 5, 0, 0, 4, 3, 2, 5, 5, 2, 5, 4, 5, 2, 2, 4, 0, 4, 1, 2, 5,\n",
            "        1, 5, 4, 0, 0, 0, 1, 5, 0, 5, 2, 4, 0, 5, 5, 5, 2, 5, 5, 3, 5, 5, 4, 4,\n",
            "        3, 5, 1, 5, 4, 5, 5, 5, 0, 2, 5, 0, 0, 0, 3, 4, 5, 0, 5, 5, 2, 1, 2, 5,\n",
            "        0, 0, 2, 5, 5, 3, 2, 4, 5, 4, 3, 2, 3, 2, 3, 0, 5, 4, 5, 5, 2, 0, 5, 5,\n",
            "        4, 5, 0, 5, 0, 0, 3, 5, 0, 5, 0, 2, 5, 0, 5, 3, 5, 4, 4, 5, 4, 1, 1, 5,\n",
            "        5, 5, 5, 0, 2, 5, 3, 1, 5, 2, 5, 5, 2, 2, 2, 5])\n",
            "tensor([1, 5, 0, 4, 0, 5, 1, 4, 0, 5, 5, 4, 5, 5, 5, 0, 0, 5, 5, 0, 5, 5, 0, 2,\n",
            "        4, 0, 0, 2, 5, 4, 4, 5, 4, 0, 3, 1, 5, 2, 3, 3, 4, 3, 5, 5, 3, 4, 2, 5,\n",
            "        5, 0, 2, 0, 4, 5, 0, 0, 5, 0, 0, 0, 4, 5, 2, 4, 5, 3, 3, 5, 5, 2, 3, 2,\n",
            "        5, 5, 5, 2, 5, 4, 5, 4, 4, 5, 0, 0, 2, 2, 5, 0, 2, 0, 3, 3, 0, 5, 2, 1,\n",
            "        1, 5, 4, 2, 5, 2, 4, 4, 1, 5, 4, 4, 5, 2, 5, 5, 5, 2, 4, 0, 0, 3, 3, 5,\n",
            "        0, 0, 1, 2, 5, 3, 0, 2, 4, 1, 5, 5, 3, 0, 2, 3, 5, 5, 3, 1, 3, 5, 0, 0,\n",
            "        3, 3, 5, 1, 5, 4, 3, 3, 4, 0, 5, 2, 4, 0, 3, 5, 5, 3, 5, 0, 2, 3, 1, 3,\n",
            "        4, 5, 5, 4, 2, 0, 1, 3, 5, 5, 4, 2, 5, 2, 3, 5, 4, 0, 3, 0, 5, 4, 4, 3,\n",
            "        3, 1, 5, 5, 0, 1, 0, 1, 2, 3, 3, 0, 3, 0, 4, 2, 5, 5, 5, 0, 2, 2, 3, 5,\n",
            "        0, 2, 4, 2, 5, 5, 3, 3, 5, 0, 5, 5, 4, 2, 5, 5, 0, 4, 5, 3, 3, 1, 0, 2,\n",
            "        3, 5, 5, 0, 5, 2, 0, 5, 0, 2, 5, 5, 3, 5, 0, 2])\n",
            "tensor([2, 5, 5, 5, 5, 0, 5, 4, 3, 1, 1, 5, 2, 2, 2, 2, 0, 1, 5, 5, 0, 2, 0, 5,\n",
            "        5, 0, 5, 3, 4, 2, 3, 5, 4, 5, 0, 5, 2, 1, 1, 5, 4, 4, 4, 5, 5, 3, 1, 0,\n",
            "        2, 4, 0, 5, 2, 5, 5, 5, 4, 0, 3, 4, 1, 5, 0, 5, 2, 3, 4, 2, 0, 1, 5, 5,\n",
            "        5, 5, 0, 3, 5, 5, 5, 2, 2, 2, 4, 0, 2, 5, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5,\n",
            "        3, 3, 4, 3, 1, 5, 1, 2, 2, 1, 4, 4, 5, 4, 5, 3, 0, 4, 4, 4, 0, 5, 5, 2,\n",
            "        0, 4, 3, 2, 5, 3, 2, 5, 3, 0, 0, 5, 1, 2, 1, 5, 1, 2, 2, 5, 5, 3, 3, 2,\n",
            "        4, 5, 3, 5, 0, 5, 1, 2, 3, 0, 0, 5, 4, 1, 5, 5, 1, 4, 0, 2, 5, 4, 3, 5,\n",
            "        5, 4, 5, 5, 3, 1, 4, 1, 0, 0, 4, 1, 3, 1, 5, 5, 3, 4, 1, 3, 5, 1, 2, 2,\n",
            "        0, 5, 5, 5, 5, 2, 3, 5, 5, 5, 2, 5, 0, 2, 1, 3, 0, 0, 2, 2, 4, 5, 0, 5,\n",
            "        1, 5, 4, 2, 5, 5, 5, 1, 3, 4, 5, 3, 5, 2, 2, 4, 5, 2, 0, 4, 5, 5, 3, 1,\n",
            "        0, 2, 2, 0, 4, 4, 4, 4, 0, 4, 4, 3, 0, 1, 4, 1])\n",
            "tensor([1, 0, 5, 0, 3, 5, 2, 3, 1, 5, 3, 0, 2, 5, 1, 0, 4, 0, 0, 2, 5, 2, 5, 4,\n",
            "        3, 2, 5, 4, 3, 2, 1, 2, 0, 3, 0, 2, 5, 0, 5, 2, 0, 0, 1, 1, 2, 3, 1, 5,\n",
            "        2, 4, 4, 0, 2, 3, 5, 3, 1, 2, 0, 5, 2, 4, 5, 4, 3, 2, 1, 2, 2, 5, 1, 2,\n",
            "        5, 0, 3, 4, 3, 2, 5, 3, 4, 0, 1, 4, 4, 1, 0, 2, 5, 4, 1, 5, 5, 5, 3, 0,\n",
            "        2, 2, 3, 4, 3, 5, 1, 1, 5, 5, 5, 5, 1, 0, 0, 1, 5, 4, 0, 5, 5, 5, 2, 5,\n",
            "        5, 3, 0, 5, 5, 5, 0, 2, 5, 3, 5, 5, 0, 5, 5, 4, 2, 0, 4, 5, 4, 0, 4, 5,\n",
            "        0, 0, 1, 5, 1, 3, 2, 1, 4, 3, 4, 2, 5, 5, 4, 5, 1, 2, 5, 5, 2, 4, 5, 2,\n",
            "        2, 5, 2, 1, 0, 5, 4, 5, 4, 0, 5, 5, 0, 5, 3, 2, 0, 3, 5, 1, 1, 4, 4, 1,\n",
            "        3, 2, 0, 2, 2, 1, 4, 4, 2, 3, 4, 5, 0, 5, 5, 5, 1, 5, 5, 4, 3, 0, 0, 2,\n",
            "        5, 0, 3, 5, 5, 0, 4, 0, 2, 4, 5, 4, 0, 4, 4, 5, 3, 4, 4, 0, 5, 2, 4, 4,\n",
            "        4, 1, 1, 1, 5, 2, 1, 2, 2, 5, 0, 0, 0, 0, 5, 4])\n",
            "tensor([3, 1, 1, 5, 1, 1, 5, 4, 4, 3, 2, 2, 3, 1, 4, 0])\n",
            "Validation Acc: 54.27\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "________"
      ],
      "metadata": {
        "id": "U2xq-SiG4Uvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = NeuralNetwork()\n",
        "# model.load_state_dict(torch.load(\"model_old.pth\"))"
      ],
      "metadata": {
        "id": "GPZXh0Ga4rZy"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def get_fisher_diag(model, dataset, params, empirical=False):\n",
        "    fisher = {}\n",
        "    params_dict = dict(params)\n",
        "    for n, p in deepcopy(params_dict).items():\n",
        "        p.data.zero_()\n",
        "        fisher[n] = p.data.clone().detach().requires_grad_()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for input, gt_label in dataset:\n",
        "        input, gt_label = input.to(device), gt_label.to(device)\n",
        "        model.zero_grad()\n",
        "        output = model(input)\n",
        "\n",
        "        if empirical:\n",
        "            label = torch.nn.functional.log_softmax(output, dim=1)\n",
        "        else:\n",
        "            label = gt_label\n",
        "\n",
        "        # label = gt_label.repeat(output.size(0))\n",
        "        negloglikelihood = torch.nn.functional.nll_loss(torch.nn.functional.log_softmax(output, dim=1), label)\n",
        "        negloglikelihood.backward()\n",
        "\n",
        "        for n, p in model.named_parameters():\n",
        "            fisher[n].data += p.grad.data ** 2 / len(dataset.dataset)\n",
        "\n",
        "    fisher = {n: p for n, p in fisher.items()}\n",
        "    return fisher\n",
        "\n",
        "\n",
        "def get_ewc_loss(model, fisher, p_old):\n",
        "    loss = 0\n",
        "    for n, p in model.named_parameters():\n",
        "        if n in fisher:\n",
        "            _loss = fisher[n] * (p - p_old[n]) ** 2\n",
        "            loss += _loss.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "LhRRttbd3Bxo"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "ewc_lambda = 0.1\n",
        "\n",
        "fisher_matrix = get_fisher_diag(model, train_dataloader_first, model.named_parameters())\n",
        "prev_params = {n: p.data.clone() for n, p in model.named_parameters()}\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "RLlF7JXB57n4"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fisher_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEtwEedKrqPc",
        "outputId": "32249af8-f023-44a9-d956-e2ce2c6fde10"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1.weight': tensor([[7.0144e-08, 7.0143e-08, 7.0107e-08,  ..., 6.7220e-08, 6.9408e-08,\n",
            "         7.0201e-08],\n",
            "        [1.2443e-07, 1.2443e-07, 1.2432e-07,  ..., 1.2133e-07, 1.2508e-07,\n",
            "         1.2461e-07],\n",
            "        [1.5954e-08, 1.5953e-08, 1.5966e-08,  ..., 1.5181e-08, 1.5586e-08,\n",
            "         1.5968e-08],\n",
            "        ...,\n",
            "        [7.1332e-09, 7.1197e-09, 7.0872e-09,  ..., 6.6002e-09, 6.9393e-09,\n",
            "         7.0660e-09],\n",
            "        [1.3719e-09, 1.3701e-09, 1.3662e-09,  ..., 1.1088e-09, 1.3093e-09,\n",
            "         1.3627e-09],\n",
            "        [9.9232e-08, 9.9229e-08, 9.9205e-08,  ..., 9.8608e-08, 9.9531e-08,\n",
            "         9.9349e-08]], requires_grad=True), 'fc1.bias': tensor([7.0152e-08, 1.2443e-07, 1.5954e-08, 1.5353e-09, 9.8909e-11, 3.6117e-08,\n",
            "        1.1840e-12, 7.1647e-10, 8.1507e-09, 1.2926e-07, 1.3513e-07, 5.5539e-08,\n",
            "        8.2039e-09, 2.4971e-07, 5.3689e-11, 1.5100e-07, 1.1359e-08, 3.4281e-08,\n",
            "        2.4150e-08, 5.6432e-11, 5.8570e-08, 1.3878e-08, 3.5874e-08, 9.7707e-09,\n",
            "        7.0594e-08, 9.1246e-11, 5.4315e-08, 1.2562e-07, 2.3050e-11, 6.4598e-08,\n",
            "        9.7203e-08, 4.5132e-08, 8.3494e-08, 1.5209e-08, 2.3840e-08, 6.8971e-08,\n",
            "        1.4199e-07, 2.5450e-07, 5.8712e-08, 2.8896e-08, 4.4863e-08, 4.1847e-08,\n",
            "        1.7220e-07, 2.0526e-08, 2.7185e-07, 7.3747e-08, 9.4214e-08, 1.2685e-07,\n",
            "        4.8991e-08, 2.1879e-08, 2.2849e-08, 1.3890e-07, 8.8937e-09, 1.4139e-07,\n",
            "        3.4346e-08, 1.9239e-09, 4.9241e-08, 3.7834e-09, 2.3380e-08, 2.9234e-07,\n",
            "        9.3248e-07, 1.6238e-08, 4.0786e-08, 2.8301e-09, 2.1174e-07, 1.3082e-09,\n",
            "        1.6099e-07, 3.0160e-08, 1.0131e-07, 5.6010e-08, 2.5219e-07, 7.1789e-09,\n",
            "        6.6769e-08, 5.1996e-08, 6.2907e-08, 4.7238e-08, 2.8076e-07, 1.5951e-07,\n",
            "        6.4857e-08, 7.0837e-08, 5.1700e-09, 1.3406e-10, 1.4379e-07, 2.5377e-08,\n",
            "        4.9537e-10, 2.0683e-08, 1.6268e-08, 2.0996e-07, 4.1490e-11, 6.5959e-08,\n",
            "        3.5803e-07, 6.6116e-10, 3.0047e-07, 1.2086e-10, 3.6100e-08, 9.6177e-08,\n",
            "        1.2092e-09, 4.6817e-08, 2.4845e-09, 2.5452e-08, 8.2468e-08, 5.9427e-08,\n",
            "        1.1130e-07, 3.6492e-08, 7.3330e-09, 2.8706e-08, 2.6731e-07, 4.2031e-08,\n",
            "        6.3633e-08, 3.0459e-08, 2.1541e-07, 2.1863e-08, 1.1405e-07, 2.4748e-09,\n",
            "        1.7632e-08, 9.6704e-08, 7.4407e-08, 3.6697e-07, 1.7010e-07, 1.8876e-09,\n",
            "        4.2908e-08, 1.8419e-07, 1.9587e-07, 3.0227e-09, 4.5411e-09, 1.3647e-07,\n",
            "        3.2997e-08, 9.8994e-08, 4.1381e-08, 1.3622e-07, 5.6519e-07, 3.3051e-08,\n",
            "        1.0021e-09, 2.8930e-07, 1.5581e-08, 2.2570e-07, 2.2669e-07, 2.5178e-09,\n",
            "        1.0822e-07, 3.5283e-08, 4.8168e-08, 1.6214e-08, 5.3637e-08, 5.9837e-09,\n",
            "        1.8410e-07, 1.8141e-10, 1.0858e-07, 1.6809e-09, 1.4444e-08, 1.4108e-07,\n",
            "        1.4669e-08, 1.5588e-08, 9.0244e-08, 1.1545e-08, 6.2622e-11, 1.8395e-08,\n",
            "        1.9601e-07, 1.5888e-08, 5.4963e-11, 6.8273e-08, 1.8158e-08, 5.3875e-08,\n",
            "        1.0991e-08, 1.4362e-09, 4.2232e-10, 6.3723e-08, 2.0189e-08, 1.1212e-10,\n",
            "        1.8696e-08, 8.2628e-08, 2.0204e-09, 2.8718e-10, 1.2630e-08, 6.5707e-11,\n",
            "        1.3140e-07, 1.7567e-07, 3.4903e-10, 6.6840e-08, 1.0199e-07, 9.3394e-08,\n",
            "        7.6527e-07, 5.4048e-09, 2.1238e-09, 3.8644e-12, 1.0838e-08, 9.5125e-08,\n",
            "        3.4422e-07, 7.5199e-09, 1.2832e-08, 2.7101e-10, 1.3209e-07, 2.0385e-07,\n",
            "        6.0962e-09, 2.6718e-08, 1.7883e-10, 2.1267e-08, 6.3234e-08, 2.5004e-07,\n",
            "        1.7991e-07, 2.0075e-07, 5.4030e-08, 1.4252e-08, 6.5263e-11, 9.1648e-08,\n",
            "        1.0417e-07, 1.9469e-07, 1.2451e-10, 2.9485e-08, 1.5871e-08, 1.0400e-10,\n",
            "        1.2983e-07, 8.0884e-08, 1.9574e-10, 1.3673e-08, 1.7041e-07, 3.6167e-11,\n",
            "        5.2889e-08, 1.7360e-07, 6.0725e-08, 1.1052e-07, 5.7634e-08, 2.6262e-08,\n",
            "        2.3134e-08, 3.0797e-08, 1.9963e-07, 6.6322e-10, 1.2410e-07, 4.6136e-08,\n",
            "        1.3080e-08, 1.1869e-07, 8.4204e-09, 1.5202e-07, 1.5910e-07, 5.0300e-09,\n",
            "        6.0111e-08, 9.6783e-10, 3.0847e-07, 3.6689e-08, 6.7249e-09, 1.5817e-07,\n",
            "        2.7663e-09, 4.3835e-08, 7.1453e-11, 3.9084e-08, 5.8387e-08, 4.3268e-08,\n",
            "        5.3391e-08, 1.3204e-08, 1.6130e-08, 2.4471e-10, 1.9244e-07, 6.9574e-08,\n",
            "        6.3437e-11, 3.9711e-08, 3.7926e-08, 7.5956e-08, 1.3416e-08, 2.2187e-07,\n",
            "        1.2790e-08, 8.6078e-09, 2.8428e-08, 1.0573e-07, 2.1826e-07, 1.1362e-07,\n",
            "        1.3680e-07, 1.0469e-07, 4.8377e-08, 1.1394e-07, 3.7371e-07, 1.0210e-07,\n",
            "        1.0262e-07, 7.5202e-08, 3.1451e-09, 3.9998e-08, 1.3178e-08, 4.0035e-09,\n",
            "        3.8066e-09, 1.3727e-07, 1.3182e-08, 4.9143e-11, 1.2474e-07, 1.7582e-07,\n",
            "        1.0859e-07, 7.8978e-08, 1.4269e-10, 3.1259e-07, 4.6517e-08, 3.4497e-08,\n",
            "        1.6535e-09, 3.9778e-08, 3.6042e-07, 1.1033e-07, 6.2474e-08, 1.7964e-07,\n",
            "        1.1450e-07, 1.2987e-07, 1.1179e-07, 5.5941e-11, 1.6058e-07, 6.4620e-08,\n",
            "        6.7091e-13, 1.7307e-07, 1.7451e-07, 3.3295e-08, 3.0895e-08, 1.6262e-08,\n",
            "        1.6813e-07, 9.4972e-08, 1.5331e-07, 3.4409e-07, 1.4639e-09, 2.9423e-09,\n",
            "        1.2600e-10, 1.4985e-07, 8.7742e-12, 2.1051e-08, 8.7065e-08, 3.6446e-09,\n",
            "        3.9144e-08, 3.0073e-07, 1.8428e-08, 5.7867e-08, 2.2371e-07, 1.8369e-07,\n",
            "        2.2760e-09, 8.4301e-09, 1.0257e-08, 1.9579e-07, 4.5155e-10, 5.6680e-08,\n",
            "        3.4697e-07, 2.8036e-10, 1.2528e-07, 2.7528e-11, 1.7705e-09, 1.0798e-07,\n",
            "        2.1849e-08, 7.0164e-11, 6.8564e-07, 2.0475e-07, 1.9439e-11, 5.8392e-08,\n",
            "        1.6334e-07, 2.7669e-08, 1.1542e-08, 1.1309e-10, 9.2479e-09, 1.5587e-08,\n",
            "        3.3292e-08, 7.0036e-08, 3.3384e-10, 3.3959e-08, 1.9450e-11, 6.9083e-08,\n",
            "        4.6213e-10, 1.9299e-07, 1.8616e-07, 6.4752e-08, 4.3563e-08, 4.5709e-11,\n",
            "        2.0576e-07, 1.0953e-07, 9.0212e-08, 1.0250e-07, 2.0574e-07, 1.1431e-07,\n",
            "        2.4834e-08, 3.4892e-07, 1.0856e-06, 1.8283e-08, 4.6670e-09, 1.4719e-10,\n",
            "        1.6054e-09, 1.9260e-08, 6.0417e-11, 3.9227e-07, 4.5116e-11, 7.0153e-08,\n",
            "        2.2152e-10, 1.5197e-07, 2.1579e-08, 1.2434e-08, 2.2148e-07, 3.6508e-08,\n",
            "        2.8802e-07, 2.5126e-09, 5.6546e-07, 6.0745e-08, 4.0047e-08, 1.6013e-07,\n",
            "        8.9847e-09, 6.8283e-09, 3.5952e-08, 1.3670e-07, 3.4051e-08, 3.1085e-08,\n",
            "        8.6067e-08, 2.7350e-08, 1.6932e-07, 2.4943e-07, 1.4809e-10, 6.4853e-08,\n",
            "        8.3540e-08, 1.1627e-11, 4.8273e-07, 4.2917e-08, 4.1488e-08, 9.6868e-08,\n",
            "        1.1952e-07, 4.3256e-08, 2.3862e-09, 1.0848e-07, 3.2879e-07, 3.4388e-08,\n",
            "        3.8545e-08, 5.3779e-09, 1.2774e-07, 1.6173e-08, 1.9519e-07, 3.6035e-08,\n",
            "        3.8230e-08, 2.4703e-07, 3.4854e-08, 2.2496e-08, 7.6599e-08, 4.1538e-08,\n",
            "        5.1060e-10, 1.9019e-08, 9.8262e-11, 1.1734e-07, 1.6808e-07, 5.8153e-08,\n",
            "        3.7490e-07, 1.9897e-08, 6.2262e-11, 2.2413e-07, 1.4872e-08, 1.2584e-07,\n",
            "        3.8068e-08, 4.9366e-08, 5.9878e-08, 1.1017e-08, 4.9829e-08, 3.7271e-08,\n",
            "        4.3568e-08, 8.3178e-08, 1.6974e-07, 3.9571e-09, 2.4143e-08, 1.6121e-09,\n",
            "        1.1089e-07, 6.0627e-11, 9.3047e-08, 1.3339e-08, 3.4559e-07, 1.6786e-09,\n",
            "        7.3077e-08, 2.5925e-10, 1.1098e-07, 1.4600e-07, 1.5244e-08, 5.2797e-08,\n",
            "        6.5866e-08, 3.2958e-07, 5.8827e-08, 1.0440e-07, 1.4764e-07, 1.0874e-07,\n",
            "        3.6399e-08, 2.1471e-08, 4.9713e-08, 1.7709e-07, 9.9907e-11, 1.0291e-07,\n",
            "        2.8095e-07, 8.4440e-08, 6.1521e-08, 7.2043e-08, 2.8592e-07, 2.6068e-08,\n",
            "        2.6774e-08, 1.2961e-07, 7.4109e-08, 1.4523e-07, 7.7096e-08, 7.3465e-08,\n",
            "        1.4185e-08, 7.5516e-08, 8.4389e-08, 6.7329e-08, 3.3632e-08, 1.4480e-07,\n",
            "        4.8037e-08, 3.3785e-08, 5.0420e-07, 6.0333e-08, 2.5836e-08, 1.4064e-08,\n",
            "        1.7286e-08, 8.8188e-08, 4.0280e-09, 4.9950e-08, 1.7257e-08, 4.7609e-08,\n",
            "        2.8015e-08, 8.3942e-08, 9.5731e-09, 8.9603e-09, 6.1425e-08, 7.1331e-09,\n",
            "        1.3719e-09, 9.9232e-08], requires_grad=True), 'fc2.weight': tensor([[5.6325e-09, 4.6044e-09, 9.2175e-10,  ..., 1.1426e-10, 1.5344e-11,\n",
            "         4.5302e-09],\n",
            "        [2.2834e-09, 1.1730e-10, 2.7202e-11,  ..., 1.8118e-10, 2.5145e-11,\n",
            "         1.3347e-09],\n",
            "        [7.7209e-10, 7.8863e-13, 4.8209e-14,  ..., 4.3885e-12, 7.0045e-13,\n",
            "         8.3038e-10],\n",
            "        ...,\n",
            "        [1.3602e-10, 1.9072e-12, 5.7862e-14,  ..., 9.7435e-14, 2.5241e-12,\n",
            "         6.4456e-11],\n",
            "        [2.0950e-09, 3.4686e-12, 3.1280e-13,  ..., 2.9564e-11, 3.3167e-12,\n",
            "         2.6108e-09],\n",
            "        [3.0980e-08, 1.7419e-08, 1.0114e-09,  ..., 3.1735e-10, 1.5845e-10,\n",
            "         1.1951e-08]], requires_grad=True), 'fc2.bias': tensor([8.2010e-09, 2.7303e-09, 7.0617e-10, 4.7177e-07, 1.5813e-07, 1.5032e-07,\n",
            "        3.4500e-08, 5.4266e-08, 2.4206e-09, 1.5571e-08, 4.8599e-11, 2.8242e-09,\n",
            "        1.1164e-07, 3.3925e-08, 3.2306e-09, 9.4392e-08, 8.0056e-08, 3.9661e-08,\n",
            "        1.6836e-07, 2.1188e-08, 1.5200e-07, 2.7569e-07, 1.9780e-07, 3.7884e-09,\n",
            "        3.7588e-08, 7.0393e-08, 1.1120e-07, 7.9906e-11, 8.8652e-09, 7.2597e-08,\n",
            "        4.0892e-08, 5.2245e-08, 1.7172e-07, 1.1108e-10, 3.0808e-07, 1.5353e-08,\n",
            "        1.4818e-09, 5.0163e-08, 5.4605e-10, 5.1048e-11, 3.7668e-09, 3.4556e-10,\n",
            "        1.8525e-09, 3.8497e-08, 1.4202e-08, 8.3267e-08, 4.7493e-08, 1.3528e-09,\n",
            "        4.4398e-07, 5.6940e-08, 1.0265e-10, 5.0395e-08, 3.0912e-08, 7.1336e-08,\n",
            "        7.5296e-10, 7.9364e-09, 6.8676e-08, 2.1322e-08, 5.3953e-08, 3.6341e-10,\n",
            "        8.5936e-11, 1.9731e-07, 2.6533e-08, 2.7484e-07, 3.2375e-08, 1.3839e-07,\n",
            "        4.0916e-08, 4.5179e-08, 1.2651e-07, 7.8314e-08, 1.7745e-07, 2.8294e-07,\n",
            "        1.0751e-07, 9.5827e-08, 7.3110e-10, 1.3517e-08, 2.1446e-07, 3.5824e-07,\n",
            "        1.1595e-08, 5.5433e-08, 2.6203e-07, 1.7515e-07, 1.3928e-07, 2.8645e-09,\n",
            "        3.4273e-08, 6.9443e-08, 1.3371e-09, 5.4358e-08, 8.5638e-08, 5.9544e-09,\n",
            "        3.0058e-08, 6.9451e-13, 6.1915e-07, 1.4485e-07, 1.0798e-07, 3.1450e-09,\n",
            "        5.2799e-08, 2.6623e-07, 6.1090e-09, 6.0212e-09, 7.7609e-09, 2.2523e-08,\n",
            "        7.6202e-08, 1.3512e-07, 5.3258e-11, 7.9356e-08, 6.7691e-09, 4.0341e-08,\n",
            "        8.4009e-11, 1.3875e-07, 1.9933e-07, 8.6170e-08, 6.8692e-08, 1.1836e-07,\n",
            "        6.1113e-07, 1.6219e-08, 2.8654e-10, 6.3080e-10, 1.1273e-07, 4.3167e-08,\n",
            "        7.9774e-08, 2.2480e-09, 6.3188e-08, 4.4303e-10, 8.8994e-08, 4.8762e-07,\n",
            "        2.6642e-07, 7.7716e-09, 6.4764e-10, 7.7236e-09, 1.1725e-10, 7.9713e-11,\n",
            "        2.5059e-09, 9.4676e-10, 1.1742e-08, 5.8090e-08, 1.8875e-07, 1.3785e-07,\n",
            "        4.2572e-08, 1.2500e-09, 3.3713e-08, 6.2470e-08, 5.1350e-08, 1.3628e-07,\n",
            "        1.2129e-11, 1.7098e-09, 1.1360e-07, 6.1224e-08, 6.0990e-09, 6.0013e-09,\n",
            "        3.3116e-08, 2.9121e-08, 5.2199e-09, 9.6824e-08, 5.8175e-08, 6.0683e-08,\n",
            "        1.2993e-07, 7.2887e-08, 9.8136e-08, 9.8797e-09, 2.7419e-08, 9.8297e-08,\n",
            "        1.3450e-07, 2.5434e-09, 2.4920e-08, 2.3383e-07, 3.2158e-08, 3.1849e-09,\n",
            "        6.4520e-08, 2.1079e-09, 3.9325e-08, 6.8008e-08, 9.7202e-09, 8.3471e-09,\n",
            "        2.2195e-07, 1.2161e-08, 9.1513e-08, 4.8438e-09, 2.5806e-08, 6.1784e-08,\n",
            "        1.3602e-07, 5.0828e-08, 3.9466e-09, 4.6539e-08, 4.5132e-08, 7.9331e-08,\n",
            "        6.2718e-09, 4.6635e-09, 5.9205e-08, 4.8328e-08, 7.2715e-08, 1.5273e-07,\n",
            "        2.2812e-08, 2.1468e-09, 3.5871e-08, 2.4980e-09, 1.2062e-09, 4.6489e-08,\n",
            "        4.1546e-11, 1.8139e-10, 1.3006e-07, 1.0242e-07, 2.2665e-08, 4.8357e-09,\n",
            "        2.4238e-08, 9.7095e-08, 4.9262e-08, 1.2500e-09, 1.6894e-07, 1.1141e-07,\n",
            "        5.8442e-08, 1.3231e-11, 2.9167e-09, 6.4919e-10, 2.2312e-08, 4.4766e-09,\n",
            "        1.1552e-09, 1.4063e-07, 1.8020e-09, 3.9404e-09, 2.1477e-09, 1.9063e-10,\n",
            "        5.5922e-11, 1.4457e-09, 2.8894e-07, 2.5862e-08, 1.5261e-09, 2.5340e-07,\n",
            "        1.7082e-07, 1.1886e-09, 9.4351e-08, 1.6529e-08, 4.6529e-08, 2.7319e-07,\n",
            "        1.6921e-07, 3.5769e-08, 1.9598e-07, 5.2139e-09, 7.1050e-08, 1.2332e-08,\n",
            "        8.8397e-08, 6.9223e-08, 4.1557e-08, 1.1131e-10, 4.9581e-08, 1.4768e-07,\n",
            "        5.3782e-08, 3.2039e-08, 1.6228e-08, 7.6990e-09, 2.1260e-08, 8.5714e-12,\n",
            "        1.0459e-07, 2.3500e-07, 9.0299e-08, 4.7131e-08, 6.6256e-08, 2.5143e-08,\n",
            "        2.3981e-07, 1.1292e-07, 5.8269e-09, 8.3885e-10, 2.8733e-08, 2.0371e-07,\n",
            "        2.3354e-08, 3.0699e-08, 1.8382e-07, 3.9102e-08, 4.0098e-08, 3.5679e-08,\n",
            "        8.7601e-08, 5.5869e-08, 3.1155e-08, 6.0543e-08, 4.2044e-09, 2.3146e-07,\n",
            "        4.3056e-08, 2.8770e-09, 1.9417e-07, 1.0534e-07, 8.0311e-10, 1.3660e-07,\n",
            "        1.0446e-07, 1.4453e-07, 6.8616e-11, 1.1643e-07, 6.2839e-08, 1.0022e-07,\n",
            "        2.7524e-10, 2.1235e-08, 7.4826e-09, 5.5888e-08, 2.5492e-09, 5.4118e-08,\n",
            "        2.4348e-08, 7.1020e-10, 9.5699e-08, 4.5774e-09, 3.9789e-08, 1.4084e-07,\n",
            "        8.1786e-08, 1.4774e-07, 3.8071e-08, 1.0739e-07, 2.9793e-07, 1.5422e-07,\n",
            "        2.5451e-08, 1.9639e-07, 9.1757e-08, 7.4267e-08, 2.7854e-07, 2.3897e-07,\n",
            "        9.9943e-09, 9.3985e-08, 9.6719e-08, 8.0248e-09, 9.4945e-08, 1.4965e-07,\n",
            "        1.0979e-08, 9.5707e-08, 1.9968e-08, 1.3028e-07, 1.7557e-08, 8.7000e-08,\n",
            "        4.0690e-08, 7.7431e-08, 5.4311e-10, 2.1454e-08, 4.7625e-09, 6.2635e-08,\n",
            "        1.0861e-07, 1.1071e-07, 1.8135e-07, 2.5170e-08, 7.1671e-08, 2.1521e-08,\n",
            "        1.5811e-07, 3.6941e-08, 2.6165e-08, 1.3018e-07, 3.4335e-08, 7.4070e-08,\n",
            "        6.3049e-09, 3.8571e-09, 5.3142e-08, 2.6582e-07, 3.0035e-08, 3.7051e-08,\n",
            "        2.5614e-10, 9.6722e-09, 4.3627e-07, 4.2324e-09, 1.9055e-07, 1.6548e-08,\n",
            "        5.3129e-10, 7.2224e-08, 1.4401e-09, 1.6251e-07, 1.1602e-08, 1.1826e-07,\n",
            "        2.0320e-09, 2.2430e-08, 2.6762e-09, 5.2481e-11, 9.1460e-08, 2.9581e-11,\n",
            "        7.2129e-10, 1.7094e-07, 8.5416e-08, 7.8997e-08, 7.9390e-10, 3.6350e-09,\n",
            "        1.1487e-07, 3.9125e-08, 1.2776e-10, 7.7426e-08, 1.2996e-07, 6.4613e-12,\n",
            "        2.3298e-08, 5.1126e-08, 4.2365e-08, 8.5130e-10, 1.8067e-09, 3.3358e-08,\n",
            "        4.0026e-08, 2.0761e-07, 1.4114e-07, 7.8036e-08, 1.0664e-09, 5.2956e-08,\n",
            "        1.8475e-08, 7.7462e-08, 9.1448e-08, 1.3197e-08, 2.6912e-09, 7.9824e-08,\n",
            "        3.3820e-07, 5.1920e-08, 6.8889e-08, 1.0085e-07, 1.0073e-07, 1.1131e-08,\n",
            "        1.0267e-08, 1.8213e-08, 8.4104e-11, 1.0038e-07, 3.2617e-08, 3.2200e-09,\n",
            "        1.3369e-09, 9.8185e-09, 4.9774e-09, 5.1820e-09, 1.7198e-07, 5.6282e-08,\n",
            "        1.3632e-07, 7.5044e-08, 1.1286e-07, 7.2477e-08, 1.2448e-08, 5.7158e-10,\n",
            "        2.3590e-08, 5.3155e-08, 1.6461e-08, 1.9140e-07, 9.8548e-08, 4.9115e-08,\n",
            "        1.5661e-07, 2.5139e-07, 1.7567e-08, 7.5234e-09, 6.9127e-08, 1.2973e-07,\n",
            "        4.3593e-10, 9.7113e-09, 7.8293e-08, 2.0925e-07, 6.1457e-10, 2.0882e-07,\n",
            "        1.1528e-08, 3.5018e-07, 3.4224e-09, 1.2377e-09, 7.1024e-08, 1.3780e-07,\n",
            "        8.3680e-08, 1.8575e-10, 3.6824e-08, 5.9203e-08, 1.9387e-08, 9.7647e-08,\n",
            "        1.3827e-07, 8.9745e-07, 1.8206e-11, 1.9963e-08, 1.4780e-07, 2.5678e-07,\n",
            "        5.4489e-08, 1.2164e-07, 3.3387e-10, 1.1144e-07, 4.8837e-08, 5.2193e-08,\n",
            "        4.3369e-09, 2.1757e-07, 5.4484e-07, 1.8365e-09, 9.5222e-08, 9.0731e-08,\n",
            "        2.8004e-08, 5.9519e-07, 8.5275e-08, 8.4277e-10, 3.2735e-08, 2.0499e-07,\n",
            "        1.8151e-07, 1.1018e-07, 1.7292e-08, 1.3342e-07, 4.2811e-08, 4.7988e-07,\n",
            "        1.4425e-07, 1.0989e-07, 1.0403e-07, 2.3743e-10, 1.8874e-07, 8.6107e-09,\n",
            "        5.7602e-10, 8.1073e-09, 3.1344e-11, 2.0439e-07, 6.1460e-09, 2.1656e-07,\n",
            "        4.5065e-09, 9.2575e-11, 1.7170e-07, 4.1673e-09, 2.4123e-07, 1.7136e-08,\n",
            "        2.0878e-07, 5.5416e-08, 1.0489e-07, 4.8401e-08, 2.6801e-09, 1.7894e-07,\n",
            "        3.3292e-09, 1.5470e-07, 6.0989e-09, 1.4914e-07, 3.0588e-10, 9.1467e-11,\n",
            "        2.3259e-09, 3.9719e-08], requires_grad=True), 'classifier.weight': tensor([[8.3728e-08, 1.6392e-08, 2.3071e-09,  ..., 2.4636e-10, 2.2151e-08,\n",
            "         1.2866e-06],\n",
            "        [4.3197e-08, 4.3891e-09, 1.2939e-10,  ..., 2.7424e-10, 1.9048e-10,\n",
            "         1.5986e-07],\n",
            "        [7.3534e-08, 5.0203e-09, 3.6664e-10,  ..., 1.1016e-10, 6.4587e-09,\n",
            "         2.4253e-06],\n",
            "        ...,\n",
            "        [4.4991e-13, 6.7247e-14, 2.1134e-15,  ..., 5.3842e-15, 1.3354e-14,\n",
            "         1.4120e-11],\n",
            "        [4.8167e-13, 6.9045e-14, 2.0161e-15,  ..., 6.8173e-15, 1.4552e-14,\n",
            "         1.4394e-11],\n",
            "        [5.0410e-13, 6.8585e-14, 1.7230e-15,  ..., 5.9201e-15, 1.2546e-14,\n",
            "         1.4952e-11]], requires_grad=True), 'classifier.bias': tensor([4.8905e-06, 1.3056e-06, 1.0030e-05, 6.1505e-06, 1.0518e-05, 1.4391e-07,\n",
            "        7.0054e-11, 7.3337e-11, 7.5863e-11, 7.7857e-11], requires_grad=True)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, fisher_matrix, prev_params):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "\n",
        "        # Original loss\n",
        "        ce_loss = loss_fn(pred, y)\n",
        "\n",
        "        # EWC loss\n",
        "        ewc_loss = get_ewc_loss(model, fisher_matrix, prev_params)\n",
        "\n",
        "        loss = ce_loss + ewc_lambda * ewc_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch+1)*len(X)\n",
        "            print(f\"Loss: {loss:>7f}, {current:>5d}/{size:>5d}\")"
      ],
      "metadata": {
        "id": "k9cHcxAN3s3Q"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(epoch):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(eval_dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            print(y)\n",
        "            _, predicted_old = outputs.max(1)\n",
        "            total += len(y)\n",
        "            correct += predicted_old.eq(y).sum().item()\n",
        "        print(f\"Validation Acc: {100. * correct / total}\\n\")"
      ],
      "metadata": {
        "id": "YOE0I97T8HAH"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    print(f\"Epoch {epoch+1}: ----------------------\")\n",
        "    train(train_dataloader_second, model, loss_fn, optimizer, fisher_matrix, prev_params)\n",
        "    test(test_dataloader_second, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv-BzHy78l06",
        "outputId": "a322b112-d3e5-4554-cb9c-449440ec4ffe"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: ----------------------\n",
            "Loss: 11.758369,    64/24000\n",
            "Loss: 0.081602,  6464/24000\n",
            "Loss: 0.303874, 12864/24000\n",
            "Loss: 0.070974, 19264/24000\n",
            "Test Error: \n",
            " Accuracy: 95.8, Avg Loss: 0.118531\n",
            "\n",
            "Epoch 2: ----------------------\n",
            "Loss: 0.129366,    64/24000\n",
            "Loss: 0.120579,  6464/24000\n",
            "Loss: 0.120792, 12864/24000\n",
            "Loss: 0.033984, 19264/24000\n",
            "Test Error: \n",
            " Accuracy: 96.2, Avg Loss: 0.103084\n",
            "\n",
            "Epoch 3: ----------------------\n",
            "Loss: 0.162501,    64/24000\n",
            "Loss: 0.049092,  6464/24000\n",
            "Loss: 0.191616, 12864/24000\n",
            "Loss: 0.028654, 19264/24000\n",
            "Test Error: \n",
            " Accuracy: 96.7, Avg Loss: 0.092145\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val(1)"
      ],
      "metadata": {
        "id": "1_oObVs6s35e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fisher_matrix = get_fisher_diag(model, train_dataloader_first, model.named_parameters())"
      ],
      "metadata": {
        "id": "srlBPxOpN8AQ"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fisher_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSXAnSI3OCIf",
        "outputId": "546d8997-a652-4022-d2de-b0cb38f52803"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1.weight': tensor([[3.8245e-11, 3.8245e-11, 3.8245e-11,  ..., 1.2485e-11, 1.2328e-11,\n",
            "         2.4805e-11],\n",
            "        [7.8698e-12, 7.8698e-12, 7.8698e-12,  ..., 2.2900e-14, 5.0570e-12,\n",
            "         6.4111e-12],\n",
            "        [2.1240e-11, 2.1240e-11, 2.1096e-11,  ..., 1.4405e-11, 1.9834e-11,\n",
            "         2.1240e-11],\n",
            "        ...,\n",
            "        [5.1814e-04, 5.1811e-04, 5.1790e-04,  ..., 4.9400e-04, 5.1294e-04,\n",
            "         5.1785e-04],\n",
            "        [1.2231e-06, 1.2230e-06, 1.2224e-06,  ..., 1.0076e-06, 1.1920e-06,\n",
            "         1.2217e-06],\n",
            "        [5.8674e-06, 5.8668e-06, 5.8624e-06,  ..., 5.8906e-06, 5.8751e-06,\n",
            "         5.8674e-06]], requires_grad=True), 'fc1.bias': tensor([3.8245e-11, 7.8698e-12, 2.1240e-11, 3.9743e-05, 2.6030e-08, 4.7503e-10,\n",
            "        5.7038e-11, 3.9195e-08, 2.4688e-11, 1.6962e-10, 3.6497e-11, 9.6668e-10,\n",
            "        2.2232e-05, 4.2485e-11, 2.2489e-09, 1.9208e-04, 3.9324e-08, 2.3227e-06,\n",
            "        4.3882e-07, 7.1989e-08, 2.8736e-11, 1.4526e-08, 7.5405e-07, 7.6080e-11,\n",
            "        4.4116e-11, 1.2728e-09, 2.5949e-06, 9.4888e-05, 4.1840e-09, 7.9859e-07,\n",
            "        1.5538e-10, 2.8498e-08, 2.9767e-07, 2.6788e-11, 6.8369e-11, 2.6987e-05,\n",
            "        0.0000e+00, 4.2660e-04, 1.8000e-06, 2.8796e-05, 3.8587e-11, 1.3553e-08,\n",
            "        0.0000e+00, 1.4073e-11, 1.0180e-09, 2.0318e-05, 2.7909e-07, 3.0794e-05,\n",
            "        1.2198e-04, 0.0000e+00, 5.6746e-07, 7.1307e-10, 1.6361e-05, 2.2176e-07,\n",
            "        1.0904e-11, 9.5106e-12, 2.2182e-08, 8.8946e-09, 1.1260e-12, 1.2757e-04,\n",
            "        8.2783e-07, 1.7799e-07, 3.0773e-07, 9.2842e-08, 4.5335e-11, 5.9766e-11,\n",
            "        3.9543e-11, 1.4719e-05, 1.0872e-10, 3.3743e-08, 8.0372e-10, 5.3711e-05,\n",
            "        2.7587e-11, 6.5985e-08, 1.3208e-04, 4.0519e-10, 1.4537e-05, 2.5115e-10,\n",
            "        0.0000e+00, 6.5326e-11, 1.3960e-06, 7.0073e-07, 6.7189e-11, 7.2840e-10,\n",
            "        6.1263e-10, 6.1218e-07, 2.6939e-08, 7.4239e-09, 5.3997e-11, 3.1219e-04,\n",
            "        2.0969e-08, 1.1390e-07, 8.1497e-09, 2.6860e-06, 4.5281e-09, 3.3244e-08,\n",
            "        9.1392e-07, 6.4707e-12, 4.8218e-05, 1.8438e-12, 8.3529e-11, 2.4936e-11,\n",
            "        3.9631e-07, 3.5271e-13, 2.1399e-06, 2.3932e-09, 1.9154e-07, 5.3274e-06,\n",
            "        8.3784e-07, 9.6095e-13, 0.0000e+00, 2.4623e-05, 2.9996e-11, 7.9165e-09,\n",
            "        4.2265e-12, 2.8969e-04, 4.3804e-11, 3.4918e-04, 0.0000e+00, 2.4005e-08,\n",
            "        3.9131e-07, 1.8880e-06, 2.3125e-04, 9.9907e-08, 0.0000e+00, 6.4635e-08,\n",
            "        7.8936e-04, 1.3736e-09, 2.2753e-06, 1.7956e-09, 8.8718e-09, 1.1211e-07,\n",
            "        1.4523e-07, 1.5330e-07, 7.8105e-07, 2.8483e-07, 4.0222e-12, 1.0187e-04,\n",
            "        1.5320e-11, 1.4818e-04, 6.7708e-13, 4.3859e-10, 0.0000e+00, 1.0755e-11,\n",
            "        1.0921e-09, 2.9056e-09, 3.2290e-05, 4.1247e-10, 2.0589e-11, 3.7352e-05,\n",
            "        9.9561e-10, 1.2778e-07, 6.1530e-08, 3.3427e-06, 2.9079e-07, 9.7518e-07,\n",
            "        5.7258e-07, 6.6600e-05, 2.3749e-10, 3.7273e-10, 1.9623e-06, 8.5769e-08,\n",
            "        2.5955e-12, 1.0179e-06, 4.1237e-06, 9.3934e-11, 8.9031e-08, 1.4257e-09,\n",
            "        3.9788e-12, 1.5109e-06, 2.1166e-10, 1.8863e-09, 5.1746e-07, 8.2402e-11,\n",
            "        0.0000e+00, 2.1714e-05, 1.4893e-08, 6.8056e-08, 1.6239e-05, 7.1643e-12,\n",
            "        1.0715e-11, 1.2414e-10, 8.4116e-07, 2.8200e-11, 6.6839e-06, 1.5691e-08,\n",
            "        6.7429e-09, 7.4244e-06, 1.5541e-08, 7.1472e-06, 2.3653e-05, 2.1892e-05,\n",
            "        5.3105e-07, 0.0000e+00, 2.0450e-10, 2.8257e-04, 2.1938e-07, 5.0504e-06,\n",
            "        1.9344e-08, 4.4129e-07, 1.2046e-05, 2.5152e-09, 5.5941e-09, 1.0318e-10,\n",
            "        5.4243e-05, 5.3121e-07, 8.6137e-07, 4.3318e-10, 9.5028e-06, 6.8543e-08,\n",
            "        3.2370e-07, 6.2282e-06, 3.7777e-10, 5.9979e-11, 4.2921e-10, 4.8646e-08,\n",
            "        4.5095e-07, 4.0633e-07, 7.7247e-12, 4.5929e-09, 1.1833e-08, 3.5616e-06,\n",
            "        1.7297e-11, 1.9085e-12, 2.9936e-12, 1.1233e-06, 1.4619e-04, 6.3561e-12,\n",
            "        9.4250e-07, 1.6439e-11, 9.9309e-12, 1.2368e-05, 2.5010e-09, 2.8920e-05,\n",
            "        2.1253e-09, 5.9859e-07, 6.2213e-09, 3.0764e-10, 1.0979e-07, 2.2898e-04,\n",
            "        1.3198e-05, 4.5609e-04, 2.7432e-09, 1.6509e-06, 1.8930e-05, 1.2385e-12,\n",
            "        1.1924e-10, 1.8607e-06, 1.6194e-11, 6.9196e-08, 4.4865e-05, 2.8212e-07,\n",
            "        1.1558e-08, 7.7224e-05, 5.9456e-12, 1.1228e-05, 3.1393e-12, 4.3344e-10,\n",
            "        5.6854e-08, 1.2319e-11, 2.8531e-06, 1.5857e-11, 1.6154e-11, 3.3833e-10,\n",
            "        3.6275e-07, 6.2493e-05, 2.5583e-10, 1.3900e-09, 7.0587e-10, 3.7568e-11,\n",
            "        1.9121e-08, 9.9339e-11, 8.0939e-05, 2.1828e-06, 4.3162e-06, 1.1884e-05,\n",
            "        5.3837e-12, 5.7621e-06, 1.3468e-11, 6.0809e-10, 2.1673e-05, 1.2718e-09,\n",
            "        1.7599e-09, 6.7192e-06, 1.1187e-09, 5.6176e-12, 0.0000e+00, 8.5869e-07,\n",
            "        9.2506e-09, 8.1380e-08, 4.3178e-07, 4.6446e-05, 2.6170e-10, 5.0784e-08,\n",
            "        8.3702e-05, 1.4796e-10, 1.5741e-07, 2.5232e-06, 1.9384e-08, 3.3568e-06,\n",
            "        6.7260e-10, 8.6052e-11, 2.5836e-05, 1.3285e-08, 5.7204e-11, 1.6469e-07,\n",
            "        5.2466e-09, 2.3285e-03, 2.5705e-10, 5.5958e-10, 3.8332e-07, 1.1996e-07,\n",
            "        4.6354e-10, 9.3930e-11, 4.6332e-09, 4.1661e-07, 8.3681e-10, 2.3757e-08,\n",
            "        9.4931e-05, 3.3913e-14, 3.1238e-09, 7.7604e-11, 1.2322e-08, 2.2923e-09,\n",
            "        1.6807e-07, 9.1545e-10, 1.2464e-04, 5.9474e-11, 1.0383e-07, 0.0000e+00,\n",
            "        1.4893e-10, 5.8970e-10, 8.8268e-11, 2.7050e-10, 8.6607e-08, 1.8282e-11,\n",
            "        3.0498e-11, 1.1271e-07, 7.2049e-10, 7.2148e-06, 8.9364e-09, 1.2023e-06,\n",
            "        3.0872e-04, 1.3777e-12, 3.6643e-10, 4.0870e-08, 1.1234e-03, 4.7861e-07,\n",
            "        3.3287e-07, 7.4034e-13, 2.6102e-10, 9.0735e-12, 1.5173e-10, 7.4976e-07,\n",
            "        2.6940e-06, 1.5097e-06, 4.0442e-08, 2.0576e-07, 8.1266e-07, 1.2382e-06,\n",
            "        8.6572e-10, 1.0267e-06, 0.0000e+00, 2.4561e-10, 5.1462e-09, 1.7272e-11,\n",
            "        1.6420e-12, 9.3497e-04, 3.4923e-10, 1.1878e-11, 1.1801e-06, 3.5237e-09,\n",
            "        3.0700e-07, 1.1030e-06, 2.0265e-10, 1.2000e-08, 1.6060e-09, 4.1229e-06,\n",
            "        2.8657e-06, 9.0895e-11, 3.8271e-07, 2.6706e-11, 3.8882e-06, 6.0883e-06,\n",
            "        7.3608e-07, 5.6109e-10, 5.2532e-09, 1.6884e-05, 2.8091e-09, 6.2498e-09,\n",
            "        4.0791e-08, 5.7987e-11, 1.2381e-14, 1.4006e-05, 5.2960e-11, 5.6377e-08,\n",
            "        2.0810e-05, 5.5028e-11, 7.2468e-09, 4.8810e-11, 1.2433e-07, 3.5229e-10,\n",
            "        1.0157e-10, 3.5007e-11, 2.1723e-03, 0.0000e+00, 1.0490e-07, 3.0384e-04,\n",
            "        7.4030e-07, 6.0703e-05, 4.0593e-08, 1.4773e-09, 3.4113e-10, 7.8115e-07,\n",
            "        4.9608e-08, 1.7688e-09, 5.2450e-11, 5.1767e-06, 3.8338e-10, 9.6237e-12,\n",
            "        0.0000e+00, 3.3503e-12, 2.1024e-09, 7.0217e-06, 1.9477e-13, 1.5788e-10,\n",
            "        4.7726e-07, 1.3119e-09, 1.4648e-10, 1.9615e-09, 1.5392e-10, 2.0107e-07,\n",
            "        2.7316e-07, 2.9410e-06, 2.6938e-06, 0.0000e+00, 2.7558e-11, 9.0067e-06,\n",
            "        1.6862e-04, 9.4103e-07, 1.1015e-10, 3.0459e-11, 2.2643e-14, 5.5888e-10,\n",
            "        2.5676e-11, 1.0501e-10, 1.3159e-11, 1.8956e-06, 1.3116e-11, 3.6348e-06,\n",
            "        1.0937e-08, 1.2651e-06, 9.8436e-11, 9.3676e-10, 2.1615e-09, 6.2165e-06,\n",
            "        1.3524e-06, 2.6782e-06, 1.5352e-09, 1.2808e-10, 2.7070e-11, 1.7121e-06,\n",
            "        2.2261e-11, 2.1711e-10, 8.4074e-10, 1.4245e-10, 2.3147e-11, 5.0194e-10,\n",
            "        2.8756e-10, 4.2501e-11, 1.4418e-05, 5.7556e-11, 2.7789e-10, 2.2113e-06,\n",
            "        1.5654e-11, 3.1679e-08, 3.9341e-09, 8.1194e-04, 1.3311e-06, 2.2229e-06,\n",
            "        5.9565e-11, 5.7664e-06, 7.0735e-07, 6.2437e-07, 7.5645e-12, 7.0098e-08,\n",
            "        1.7159e-08, 1.2747e-10, 1.6634e-09, 5.0778e-08, 2.0944e-07, 7.0173e-11,\n",
            "        9.2146e-08, 5.3980e-05, 2.6093e-05, 5.2790e-05, 2.6340e-10, 5.1141e-04,\n",
            "        4.5332e-06, 0.0000e+00, 3.0548e-06, 7.5480e-09, 5.2942e-06, 6.9414e-11,\n",
            "        5.5727e-05, 3.0547e-07, 5.0211e-05, 1.3655e-05, 5.2846e-04, 5.1814e-04,\n",
            "        1.2231e-06, 5.8675e-06], requires_grad=True), 'fc2.weight': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1457e-11, 4.0730e-12,\n",
            "         1.2787e-10],\n",
            "        [6.4452e-11, 2.5615e-11, 8.3458e-12,  ..., 9.4433e-05, 5.5639e-07,\n",
            "         7.1845e-06],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.7768e-10, 1.4301e-12,\n",
            "         4.9227e-10],\n",
            "        ...,\n",
            "        [0.0000e+00, 3.7825e-13, 5.6625e-13,  ..., 2.2636e-06, 3.9729e-09,\n",
            "         6.6566e-07],\n",
            "        [0.0000e+00, 0.0000e+00, 1.3881e-13,  ..., 1.4873e-06, 1.8364e-08,\n",
            "         3.1328e-07],\n",
            "        [0.0000e+00, 0.0000e+00, 2.3894e-13,  ..., 1.7369e-13, 6.9737e-12,\n",
            "         0.0000e+00]], requires_grad=True), 'fc2.bias': tensor([4.6277e-11, 7.3891e-05, 3.5891e-10, 8.0027e-08, 2.6725e-04, 4.6677e-04,\n",
            "        1.6629e-07, 5.0408e-05, 1.9167e-06, 9.4844e-08, 3.3679e-11, 3.2904e-08,\n",
            "        2.5380e-05, 1.4100e-05, 4.7624e-04, 1.3722e-05, 1.0149e-06, 4.3896e-08,\n",
            "        6.1003e-05, 3.8246e-05, 2.4610e-09, 3.4376e-07, 8.4354e-07, 1.2058e-06,\n",
            "        1.0482e-05, 1.8627e-06, 1.0882e-06, 1.9506e-04, 0.0000e+00, 2.6125e-09,\n",
            "        4.5628e-05, 5.5617e-08, 2.0778e-07, 1.6113e-06, 5.4565e-07, 2.1060e-04,\n",
            "        1.4355e-06, 2.3867e-07, 2.9807e-06, 1.4299e-04, 3.0139e-09, 1.7877e-06,\n",
            "        1.1669e-05, 1.0855e-05, 7.2324e-06, 5.2256e-09, 1.0448e-06, 9.4640e-06,\n",
            "        0.0000e+00, 0.0000e+00, 5.1965e-06, 1.5273e-07, 2.0246e-08, 1.3628e-09,\n",
            "        4.2513e-10, 5.9190e-06, 5.2159e-06, 6.2377e-10, 4.1336e-06, 9.8745e-05,\n",
            "        6.9100e-07, 5.5306e-07, 2.0367e-04, 0.0000e+00, 1.3881e-04, 3.7976e-06,\n",
            "        1.7668e-05, 2.1599e-05, 0.0000e+00, 1.2503e-05, 8.1648e-06, 0.0000e+00,\n",
            "        7.4365e-09, 0.0000e+00, 5.2236e-08, 8.8108e-07, 1.9458e-07, 2.0264e-05,\n",
            "        3.5776e-09, 1.0131e-04, 1.1499e-10, 1.9606e-09, 9.7041e-08, 1.2256e-04,\n",
            "        0.0000e+00, 4.2392e-09, 5.5804e-06, 0.0000e+00, 6.4414e-05, 1.0042e-06,\n",
            "        1.8750e-06, 7.3338e-09, 4.0309e-09, 5.5152e-08, 3.1540e-04, 3.0572e-04,\n",
            "        6.9619e-06, 0.0000e+00, 5.1199e-06, 9.2859e-08, 8.5008e-05, 5.3600e-08,\n",
            "        3.6762e-05, 4.3636e-06, 0.0000e+00, 1.6391e-06, 2.1470e-06, 2.6536e-06,\n",
            "        6.8315e-05, 2.0274e-05, 1.0173e-08, 0.0000e+00, 5.2530e-05, 0.0000e+00,\n",
            "        0.0000e+00, 1.4479e-04, 1.1425e-06, 9.8568e-06, 9.9713e-06, 5.1393e-12,\n",
            "        0.0000e+00, 1.2723e-07, 0.0000e+00, 4.5021e-11, 0.0000e+00, 0.0000e+00,\n",
            "        2.3288e-05, 1.0798e-05, 2.4101e-05, 3.9407e-07, 8.2957e-08, 1.1996e-06,\n",
            "        1.1832e-05, 1.2991e-06, 9.6408e-05, 2.9146e-11, 8.3817e-07, 0.0000e+00,\n",
            "        1.2008e-05, 2.6597e-07, 0.0000e+00, 3.5584e-08, 5.8448e-04, 6.0193e-06,\n",
            "        2.6034e-08, 0.0000e+00, 2.8524e-09, 2.0172e-08, 5.3741e-05, 2.0528e-04,\n",
            "        5.0352e-10, 1.5374e-06, 5.2622e-09, 8.1367e-08, 0.0000e+00, 0.0000e+00,\n",
            "        2.1883e-10, 1.2001e-04, 3.3455e-04, 0.0000e+00, 5.7901e-08, 4.7213e-06,\n",
            "        3.8678e-08, 6.2613e-05, 1.2803e-05, 0.0000e+00, 2.4792e-06, 5.5618e-05,\n",
            "        1.8755e-11, 1.4195e-07, 0.0000e+00, 1.5198e-04, 6.3125e-11, 4.2065e-08,\n",
            "        0.0000e+00, 1.3607e-04, 5.1230e-07, 5.9135e-05, 0.0000e+00, 3.6734e-05,\n",
            "        2.2222e-09, 2.0659e-05, 0.0000e+00, 1.8232e-06, 7.4234e-11, 1.6427e-06,\n",
            "        1.2336e-04, 1.5078e-07, 3.8892e-08, 3.1390e-08, 1.7718e-07, 9.7586e-06,\n",
            "        6.5107e-08, 2.2105e-06, 2.8145e-09, 9.7141e-05, 8.6258e-06, 3.2015e-07,\n",
            "        1.9716e-04, 5.5275e-11, 0.0000e+00, 3.1048e-11, 1.0100e-06, 4.5729e-06,\n",
            "        1.1429e-08, 2.2976e-06, 1.4202e-09, 8.0305e-07, 2.3792e-06, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.8651e-09, 6.6587e-09, 2.0861e-11, 5.7076e-05,\n",
            "        7.9347e-06, 2.2007e-06, 1.3878e-05, 1.6813e-04, 2.9943e-05, 2.9302e-06,\n",
            "        1.1920e-07, 1.6403e-06, 2.0650e-04, 2.3535e-06, 6.4914e-08, 0.0000e+00,\n",
            "        7.3143e-05, 6.4332e-08, 2.8967e-10, 7.5413e-06, 3.7110e-04, 1.2389e-07,\n",
            "        6.7866e-11, 2.8312e-05, 2.9551e-08, 0.0000e+00, 0.0000e+00, 7.7899e-05,\n",
            "        6.4491e-11, 1.7150e-05, 5.1901e-07, 4.5170e-08, 5.5519e-06, 7.2858e-08,\n",
            "        5.4839e-12, 4.7303e-05, 7.8524e-11, 2.4394e-08, 7.2535e-08, 6.3223e-11,\n",
            "        3.4435e-11, 1.3967e-06, 4.8761e-07, 2.5121e-05, 0.0000e+00, 8.6812e-10,\n",
            "        5.1603e-09, 2.4981e-08, 1.7051e-04, 7.8326e-05, 1.5977e-09, 1.0976e-04,\n",
            "        9.5998e-06, 8.2904e-05, 0.0000e+00, 8.0018e-07, 3.6350e-04, 0.0000e+00,\n",
            "        2.9668e-08, 1.4947e-05, 1.1365e-11, 3.4595e-11, 7.8293e-06, 2.5273e-09,\n",
            "        0.0000e+00, 2.3462e-09, 0.0000e+00, 2.0095e-10, 4.3444e-11, 2.0738e-04,\n",
            "        3.5180e-06, 7.3206e-06, 2.1200e-06, 3.3912e-09, 1.0737e-06, 8.8002e-05,\n",
            "        1.4023e-04, 1.6206e-06, 3.1960e-06, 1.9304e-06, 2.9088e-06, 5.0360e-08,\n",
            "        1.0191e-05, 3.0126e-06, 0.0000e+00, 3.6655e-12, 1.7582e-05, 1.4603e-12,\n",
            "        1.3298e-05, 8.8937e-06, 5.0132e-11, 1.9978e-11, 2.3403e-04, 1.3313e-06,\n",
            "        3.2796e-05, 1.2142e-05, 0.0000e+00, 0.0000e+00, 9.0580e-06, 7.0109e-10,\n",
            "        5.3188e-09, 2.3986e-04, 5.0196e-07, 3.8341e-07, 7.3747e-04, 4.1113e-08,\n",
            "        1.7075e-06, 5.3385e-05, 2.2605e-06, 4.3784e-06, 4.7670e-04, 7.4263e-06,\n",
            "        1.7204e-05, 5.8084e-06, 2.9959e-06, 1.3014e-06, 1.1052e-05, 0.0000e+00,\n",
            "        6.0525e-04, 2.0156e-08, 1.9819e-05, 2.0416e-05, 3.8281e-05, 2.2009e-05,\n",
            "        1.9526e-06, 0.0000e+00, 4.7507e-06, 0.0000e+00, 5.9051e-09, 1.2843e-09,\n",
            "        7.5887e-06, 1.1701e-05, 2.4335e-05, 3.0682e-04, 3.4337e-11, 2.3601e-07,\n",
            "        2.3918e-06, 1.0965e-05, 2.3817e-11, 4.4964e-06, 6.0748e-11, 2.4166e-04,\n",
            "        2.8325e-05, 2.3240e-07, 2.1382e-10, 2.7078e-11, 3.1022e-08, 1.0472e-10,\n",
            "        3.1701e-05, 8.3833e-05, 8.3809e-11, 1.1052e-04, 0.0000e+00, 2.2021e-08,\n",
            "        8.8723e-06, 3.9823e-06, 4.6138e-04, 9.9210e-08, 1.5690e-05, 6.5289e-05,\n",
            "        2.0016e-06, 4.4977e-07, 1.8921e-04, 4.3030e-10, 4.2450e-11, 2.1424e-06,\n",
            "        3.1787e-04, 3.8730e-10, 3.5967e-04, 2.9265e-09, 1.7788e-07, 7.9667e-06,\n",
            "        0.0000e+00, 5.4425e-08, 1.0696e-06, 3.9921e-05, 2.5529e-09, 1.2872e-04,\n",
            "        2.0928e-06, 1.2670e-04, 7.8443e-11, 2.0684e-04, 1.7919e-04, 1.1055e-06,\n",
            "        1.9612e-06, 1.5058e-05, 8.0390e-08, 2.0556e-04, 1.2663e-10, 3.4199e-05,\n",
            "        1.3303e-05, 6.5369e-07, 3.0568e-05, 0.0000e+00, 1.2732e-07, 2.1842e-09,\n",
            "        1.0269e-05, 2.0907e-05, 2.0504e-11, 6.8695e-05, 1.1366e-06, 8.3071e-05,\n",
            "        6.1055e-05, 1.3503e-05, 1.7679e-05, 4.6223e-06, 2.1310e-04, 5.8163e-06,\n",
            "        0.0000e+00, 4.2472e-06, 3.2225e-09, 2.1708e-05, 2.3864e-04, 1.4907e-04,\n",
            "        0.0000e+00, 0.0000e+00, 9.4224e-06, 1.2665e-07, 2.5091e-07, 3.8202e-05,\n",
            "        3.7042e-07, 7.5512e-05, 0.0000e+00, 9.2775e-05, 3.6879e-07, 9.3402e-05,\n",
            "        1.8382e-06, 1.3798e-10, 7.5418e-06, 7.2283e-05, 1.4140e-05, 1.5749e-06,\n",
            "        0.0000e+00, 4.2669e-08, 1.0042e-08, 1.6046e-09, 1.8405e-12, 2.0619e-10,\n",
            "        9.1071e-05, 0.0000e+00, 6.0358e-06, 1.7061e-07, 3.1999e-05, 9.8362e-06,\n",
            "        9.1974e-08, 0.0000e+00, 5.4722e-06, 5.6956e-06, 4.4471e-10, 3.8584e-05,\n",
            "        9.8620e-07, 5.8407e-05, 4.4002e-04, 7.6798e-06, 8.3358e-09, 5.7505e-10,\n",
            "        1.5737e-09, 6.0450e-11, 5.3684e-11, 7.6080e-10, 5.4028e-05, 9.0225e-05,\n",
            "        1.1779e-09, 3.7791e-11, 3.4303e-06, 1.8625e-06, 0.0000e+00, 2.7220e-09,\n",
            "        1.1436e-10, 7.5702e-08, 4.6301e-04, 8.2113e-07, 9.9810e-05, 0.0000e+00,\n",
            "        2.5633e-05, 2.6834e-05, 2.7275e-11, 7.5788e-07, 1.1032e-06, 7.8735e-07,\n",
            "        1.5145e-09, 6.8265e-13, 0.0000e+00, 3.6304e-06, 0.0000e+00, 1.3378e-04,\n",
            "        0.0000e+00, 4.6369e-05, 3.2754e-05, 1.0734e-08, 1.1855e-07, 2.1403e-09,\n",
            "        1.0704e-10, 3.8960e-12, 8.9868e-09, 7.9363e-12, 1.6927e-11, 2.7597e-06,\n",
            "        1.4960e-06, 9.9926e-12], requires_grad=True), 'classifier.weight': tensor([[9.3327e-12, 4.3215e-04, 5.0858e-10,  ..., 2.7460e-06, 5.5811e-06,\n",
            "         8.0509e-12],\n",
            "        [9.8822e-20, 1.9775e-04, 2.6883e-12,  ..., 8.2157e-06, 8.0236e-06,\n",
            "         5.4900e-18],\n",
            "        [1.3150e-11, 4.3917e-04, 4.1551e-11,  ..., 1.0839e-07, 2.3622e-06,\n",
            "         3.1965e-19],\n",
            "        ...,\n",
            "        [9.4805e-22, 4.1179e-06, 1.6581e-14,  ..., 1.6295e-10, 2.4788e-08,\n",
            "         1.8946e-18],\n",
            "        [6.7468e-16, 3.4995e-05, 2.8697e-11,  ..., 1.2696e-07, 2.1618e-07,\n",
            "         6.9427e-12],\n",
            "        [2.7364e-21, 5.0688e-05, 1.8574e-16,  ..., 2.1457e-09, 1.6815e-10,\n",
            "         1.9548e-17]], requires_grad=True), 'classifier.bias': tensor([4.6755e-04, 4.6999e-04, 4.6763e-04, 4.6769e-04, 4.6464e-04, 4.7385e-04,\n",
            "        9.8052e-03, 1.5543e-04, 5.1381e-05, 7.0161e-05], requires_grad=True)}\n"
          ]
        }
      ]
    }
  ]
}